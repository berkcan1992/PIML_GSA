{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from numpy.linalg import cholesky, det, lstsq\n",
    "from scipy.optimize import minimize\n",
    "import scipy.spatial.distance as spdist\n",
    "\n",
    "def pass_arg(Xx, nsim, tr_size):\n",
    "\n",
    "    # Compute the RMSE\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred-y_true)**2))\n",
    "    \n",
    "    print(\"tr_Size:\",tr_size)\n",
    "    # Load labeled data\n",
    "    data = np.loadtxt('../data/labeled_data.dat')\n",
    "    x_labeled = data[:, :2].astype(np.float64) # -2 because we do not need porosity predictions\n",
    "    y_labeled = data[:, -2:-1].astype(np.float64) # dimensionless bond length and porosity measurements\n",
    "\n",
    "    # normalize dataset with MinMaxScaler\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "    x_labeled = scaler.fit_transform(x_labeled)\n",
    "    # y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "    tr_size = int(tr_size)\n",
    "\n",
    "    # train and test data\n",
    "    trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "    testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "    \n",
    "    def covSEard(hyp=None, x=None, z=None):\n",
    "        ''' Squared Exponential covariance function with Automatic Relevance Detemination\n",
    "         (ARD) distance measure. The covariance function is parameterized as:\n",
    "\n",
    "         k(x^p,x^q) = sf2 * exp(-(x^p - x^q)' * inv(P) * (x^p - x^q)/2)\n",
    "\n",
    "         where the P matrix is diagonal with ARD parameters ell_1^2,...,ell_D^2, where\n",
    "         D is the dimension of the input space and sf2 is the signal variance.\n",
    "\n",
    "         The hyperparameters are:\n",
    "\n",
    "         hyp = [ log(ell_1)\n",
    "                 log(ell_2)\n",
    "                 ...\n",
    "                 log(ell_D)\n",
    "                 log(sqrt(sf2)) ]\n",
    "        '''\n",
    "\n",
    "        [n, D] = x.shape\n",
    "        ell = 1/np.array(hyp[0:D])        # characteristic length scale\n",
    "        \n",
    "        \n",
    "        sf2 = np.array(hyp[D])**2         # signal variance\n",
    "        tmp = np.dot(np.diag(ell),x.T).T\n",
    "        A = spdist.cdist(np.dot(np.diag(ell),x.T).T, np.dot(np.diag(ell),z.T).T, 'sqeuclidean') # cross covariances\n",
    "\n",
    "        A = sf2*np.exp(-0.5*A)  \n",
    "\n",
    "        return A\n",
    "\n",
    "\n",
    "    def posterior_predictive(X_s, X_train, Y_train, l1=.1, l2=.1, sigma_f=.1, sigma_y=1e-5):\n",
    "        '''  \n",
    "        Computes the suffifient statistics of the GP posterior predictive distribution \n",
    "        from m training data X_train and Y_train and n new inputs X_s.\n",
    "\n",
    "        Args:\n",
    "            X_s: New input locations (n x d).\n",
    "            X_train: Training locations (m x d).\n",
    "            Y_train: Training targets (m x 1).\n",
    "            l: Kernel length parameter.\n",
    "            sigma_f: Kernel vertical variation parameter.\n",
    "            sigma_y: Noise parameter.\n",
    "\n",
    "        Returns:\n",
    "            Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "        '''\n",
    "\n",
    "\n",
    "        K = covSEard(hyp=[l1,l2,sigma_f], x=X_train, z=X_train) + sigma_y**2 * np.eye(len(X_train))\n",
    "        K_s = covSEard(hyp=[l1,l2,sigma_f], x=X_train, z=X_s)\n",
    "        K_ss = covSEard(hyp=[l1,l2,sigma_f], x=X_s, z=X_s)  + 1e-8 * np.eye(len(X_s))\n",
    "#         K_inv = inv(K)\n",
    "        K_inv = np.linalg.pinv(K)\n",
    "    \n",
    "        # Equation (4)\n",
    "        mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
    "\n",
    "        # Equation (5)\n",
    "        cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "        \n",
    "        return mu_s, cov_s\n",
    "\n",
    "\n",
    "    def nll_fn(X_train, Y_train, noise=0, naive=False):\n",
    "        '''\n",
    "        Returns a function that computes the negative log marginal\n",
    "        likelihood for training data X_train and Y_train and given \n",
    "        noise level.\n",
    "\n",
    "        Args:\n",
    "            X_train: training locations (m x d).\n",
    "            Y_train: training targets (m x 1).\n",
    "            noise: known noise level of Y_train.\n",
    "            naive: if True use a naive implementation of Eq. (7), if \n",
    "                   False use a numerically more stable implementation. \n",
    "\n",
    "        Returns:\n",
    "            Minimization objective.\n",
    "        '''\n",
    "\n",
    "        def nll_stable(theta):\n",
    "            # Numerically more stable implementation of Eq. (7) as described\n",
    "            # in http://www.gaussianprocess.org/gpml/chapters/RW2.pdf, Section\n",
    "            # 2.2, Algorithm 2.1.\n",
    "            K = covSEard(hyp=[theta[0],theta[1],theta[2]], x=X_train, z=X_train) + \\\n",
    "                theta[3]**2 * np.eye(len(X_train))\n",
    "            \n",
    "            K += 1e-6 * np.eye(*K.shape)\n",
    "            L = cholesky(K)\n",
    "            return np.sum(np.log(np.diagonal(L))) + \\\n",
    "                   0.5 * Y_train.T.dot(lstsq(L.T, lstsq(L, Y_train)[0])[0]) + \\\n",
    "                   0.5 * len(X_train) * np.log(2*np.pi)\n",
    "\n",
    "        if naive:\n",
    "            return nll_naive\n",
    "        else:\n",
    "            return nll_stable\n",
    "\n",
    "    \n",
    "    # Optimization\n",
    "    res = minimize(nll_fn(trainX, trainY), x0 = [.1, .1, .1, 1e-3], \n",
    "                   bounds=((1e-5, None), (1e-5, None), (1e-5, None), (1e-7, None)),\n",
    "                    method='L-BFGS-B')\n",
    "    \n",
    "#     print(f'After parameter optimization: l1={res.x[0]:.5f} l2={res.x[1]:.5f} sigma_f={res.x[2]:.5f}')\n",
    "#     print(np.exp(res.x[0]),np.exp(res.x[1]), np.exp(res.x[2]))\n",
    "    mu_s, cov_s = posterior_predictive(testX, trainX, trainY, *res.x)\n",
    "    \n",
    "    RMSE = []\n",
    "    for ii in range(int(nsim)):\n",
    "        samples = np.random.multivariate_normal(mu_s.ravel(), cov_s, 1)\n",
    "        RMSE.append(root_mean_squared_error(testY, samples))\n",
    "        \n",
    "        print(\"RMSE:\", root_mean_squared_error(testY, samples))\n",
    "\n",
    "    return samples, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:123: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.020927216653475734\n",
      "RMSE: 0.018441895119178184\n",
      "RMSE: 0.019271874735847325\n",
      "RMSE: 0.019980323115343465\n",
      "RMSE: 0.020794386542645333\n",
      "RMSE: 0.019890442340386325\n",
      "RMSE: 0.020534284069476876\n",
      "RMSE: 0.018888610532204704\n",
      "RMSE: 0.021266036277031938\n",
      "RMSE: 0.020651745011600157\n",
      "RMSE: 0.0205613334349761\n",
      "RMSE: 0.01910176355986001\n",
      "RMSE: 0.018871909291490303\n",
      "RMSE: 0.01986569859217515\n",
      "RMSE: 0.01967895101831376\n",
      "RMSE: 0.01872113803789104\n",
      "RMSE: 0.02077159112523238\n",
      "RMSE: 0.019381342147298242\n",
      "RMSE: 0.01987038397350114\n",
      "RMSE: 0.018772186965917\n",
      "RMSE: 0.019157390766193425\n",
      "RMSE: 0.0205449178007946\n",
      "RMSE: 0.022111427056225763\n",
      "RMSE: 0.019713421343422424\n",
      "RMSE: 0.01840591548761856\n",
      "RMSE: 0.01979945357780922\n",
      "RMSE: 0.02031470664153936\n",
      "RMSE: 0.018441229878817803\n",
      "RMSE: 0.021041937567796595\n",
      "RMSE: 0.020289436292011652\n",
      "RMSE: 0.020731274708010332\n",
      "RMSE: 0.01906711227001113\n",
      "RMSE: 0.020848201042930073\n",
      "RMSE: 0.02098213361843857\n",
      "RMSE: 0.017446400055922972\n",
      "RMSE: 0.020488030857892546\n",
      "RMSE: 0.021296020927538708\n",
      "RMSE: 0.0192968113194208\n",
      "RMSE: 0.018153788098883763\n",
      "RMSE: 0.02062302315903294\n",
      "RMSE: 0.019590697209711624\n",
      "RMSE: 0.019476068674390626\n",
      "RMSE: 0.01987373325416408\n",
      "RMSE: 0.01822500625730206\n",
      "RMSE: 0.020441732229761662\n",
      "RMSE: 0.02121309410215025\n",
      "RMSE: 0.020886942792400862\n",
      "RMSE: 0.01960418937265175\n",
      "RMSE: 0.0200514158292085\n",
      "RMSE: 0.019437198233436027\n",
      "RMSE: 0.02028264642071511\n",
      "RMSE: 0.01907055071132196\n",
      "RMSE: 0.019908438391994073\n",
      "RMSE: 0.020764645425080407\n",
      "RMSE: 0.020098903586275613\n",
      "RMSE: 0.019059567711337586\n",
      "RMSE: 0.01868888310202738\n",
      "RMSE: 0.019888285722526617\n",
      "RMSE: 0.018753098345450192\n",
      "RMSE: 0.019788762116241653\n",
      "RMSE: 0.01932798488389126\n",
      "RMSE: 0.01897769903763917\n",
      "RMSE: 0.019780990991267837\n",
      "RMSE: 0.019728828476113104\n",
      "RMSE: 0.020245535938153494\n",
      "RMSE: 0.020122831217039932\n",
      "RMSE: 0.020118413254544307\n",
      "RMSE: 0.020502462764184933\n",
      "RMSE: 0.01885824628390718\n",
      "RMSE: 0.019151504871974038\n",
      "RMSE: 0.019601291458815763\n",
      "RMSE: 0.019710583623976513\n",
      "RMSE: 0.018158585215348307\n",
      "RMSE: 0.02012634719465395\n",
      "RMSE: 0.019074613501537854\n",
      "RMSE: 0.01901520540372967\n",
      "RMSE: 0.02067480756266044\n",
      "RMSE: 0.020223236561239023\n",
      "RMSE: 0.019802093733707567\n",
      "RMSE: 0.02136727733150009\n",
      "RMSE: 0.021782679726571393\n",
      "RMSE: 0.020140840065853635\n",
      "RMSE: 0.01876479121468441\n",
      "RMSE: 0.019210563355856688\n",
      "RMSE: 0.020364018566097014\n",
      "RMSE: 0.020686593405776565\n",
      "RMSE: 0.018826462413650418\n",
      "RMSE: 0.01904814445054325\n",
      "RMSE: 0.021047097486601368\n",
      "RMSE: 0.019094123482982225\n",
      "RMSE: 0.019763579102493156\n",
      "RMSE: 0.020025497885851402\n",
      "RMSE: 0.020278751252386044\n",
      "RMSE: 0.021650886374060645\n",
      "RMSE: 0.0191540229291528\n",
      "RMSE: 0.020550879627062868\n",
      "RMSE: 0.021444071757678287\n",
      "RMSE: 0.02019988300558749\n",
      "RMSE: 0.019912155468779894\n",
      "RMSE: 0.018968323184955116\n"
     ]
    }
   ],
   "source": [
    "Xx = np.random.uniform(size=(1, 2))\n",
    "ss, rmse = pass_arg(Xx, 100, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019855815085648133"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = np.random.uniform(size=(3, 2))\n",
    "ss = pass_arg(Xx, 1, 30)\n",
    "# print(ss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
