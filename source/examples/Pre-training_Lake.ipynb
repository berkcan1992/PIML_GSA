{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def PGNN_train_test(optimizer_name, optimizer_val, drop_rate, iteration, n_layers, n_nodes,\n",
    "                    tr_size, lake_name, use_YPhy):\n",
    "        \n",
    "    # Hyper-parameters of the training process\n",
    "#     batch_size = int(tr_size/2)\n",
    "    batch_size = 1000\n",
    "    num_epochs = 1000\n",
    "    val_frac = 0.25\n",
    "    patience_val = 100\n",
    "    \n",
    "    # Initializing results filename\n",
    "    exp_name = \"Scaled_Lake_Pre-train\" + optimizer_name + '_drop' + str(drop_rate) + '_nL' + str(n_layers) + '_nN' + str(n_nodes) + '_trsize' + str(tr_size) + '_iter' + str(iteration)\n",
    "    exp_name = exp_name.replace('.','pt')\n",
    "    results_dir = '../../results/Lake/'\n",
    "    model_name = results_dir + exp_name + '.h5' # storing the trained model\n",
    "    results_name = results_dir + exp_name + '_results.dat' # storing the results of the model\n",
    "    \n",
    "    # Loading unsupervised data\n",
    "    data_dir = '../../data/'\n",
    "    unsup_filename = lake_name + '_sampled.mat'\n",
    "    unsup_mat = spio.loadmat(data_dir+unsup_filename, squeeze_me=True,\n",
    "    variable_names=['Xc_doy1','Xc_doy2'])\n",
    "    \n",
    "    uX1 = unsup_mat['Xc_doy1'] # Xc at depth i for every pair of consecutive depth values\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    uX1 = scaler.fit_transform(uX1)\n",
    "\n",
    "    uY1 = uX1[:,-1]\n",
    "    uX1 = uX1[:,:-1]\n",
    "#     uX2 = unsup_mat['Xc_doy2'] # Xc at depth i + 1 for every pair of consecutive depth values\n",
    "\n",
    "\n",
    "    \n",
    "    # train and test data\n",
    "    trainX, testX, trainY, testY = train_test_split(uX1, uY1, train_size=tr_size/uX1.shape[0], \n",
    "                                                    test_size=100/uX1.shape[0], random_state=42, shuffle=True)\n",
    "\n",
    "    \n",
    "#     # train and test data\n",
    "#     trainX, trainY = uX1[:tr_size,:], uY1[:tr_size]\n",
    "#     testX, testY = uX1[tr_size:,:], uY1[tr_size:]\n",
    "    \n",
    "    # Creating the model\n",
    "    model = Sequential()\n",
    "    for layer in np.arange(n_layers):\n",
    "        if layer == 0:\n",
    "            model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "        else:\n",
    "#              model.add(Dense(n_nodes, activation='relu'))\n",
    "            model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)))\n",
    "        model.add(Dropout(rate=drop_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer_val,\n",
    "                  metrics=[root_mean_squared_error])\n",
    "    \n",
    "    \n",
    "#     with tf.Session() as sess:\n",
    "#         init = tf.global_variables_initializer()\n",
    "#         sess.run(init)\n",
    "#         print(predictions[:,0].eval())\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val,verbose=1)\n",
    "    \n",
    "    print('Running...' + optimizer_name)\n",
    "    history = model.fit(trainX, trainY,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        verbose=1,\n",
    "                        validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "#     print(testX)\n",
    "    test_score = model.evaluate(testX, testY, verbose=0)\n",
    "    print(test_score[0], test_score[1])\n",
    "    print('iter: ' + str(iteration) + \n",
    "          ' nL: ' + str(n_layers) + ' nN: ' + str(n_nodes) + \n",
    "          ' trsize: ' + str(tr_size) + \n",
    "          ' TestRMSE: ' + str(test_score[1]))\n",
    "    \n",
    "#     predictions = model.predict(uX1) # model output at depth i\n",
    "#     print(np.sort(predictions[:,0], axis=0))\n",
    "    \n",
    "    model.save(model_name)\n",
    "    \n",
    "    # save results\n",
    "    dictnry = {'train_rmse':history.history['root_mean_squared_error'], \n",
    "                                'val_rmse':history.history['val_root_mean_squared_error'],\n",
    "                                'test_rmse':test_score[1]}\n",
    "\n",
    "    return dictnry, results_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...Adam\n",
      "Train on 450000 samples, validate on 150000 samples\n",
      "Epoch 1/1000\n",
      "450000/450000 [==============================] - 1s 3us/step - loss: 0.3868 - root_mean_squared_error: 0.4308 - val_loss: 0.1708 - val_root_mean_squared_error: 0.2734\n",
      "Epoch 2/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.1941 - root_mean_squared_error: 0.3001 - val_loss: 0.1267 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 3/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.1497 - root_mean_squared_error: 0.2654 - val_loss: 0.0998 - val_root_mean_squared_error: 0.2113\n",
      "Epoch 4/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.1251 - root_mean_squared_error: 0.2439 - val_loss: 0.0839 - val_root_mean_squared_error: 0.1982\n",
      "Epoch 5/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.1114 - root_mean_squared_error: 0.2305 - val_loss: 0.0739 - val_root_mean_squared_error: 0.1856\n",
      "Epoch 6/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.1031 - root_mean_squared_error: 0.2222 - val_loss: 0.0686 - val_root_mean_squared_error: 0.1808\n",
      "Epoch 7/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0970 - root_mean_squared_error: 0.2157 - val_loss: 0.0644 - val_root_mean_squared_error: 0.1737\n",
      "Epoch 8/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0925 - root_mean_squared_error: 0.2119 - val_loss: 0.0641 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 9/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0901 - root_mean_squared_error: 0.2099 - val_loss: 0.0617 - val_root_mean_squared_error: 0.1715\n",
      "Epoch 10/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0880 - root_mean_squared_error: 0.2086 - val_loss: 0.0612 - val_root_mean_squared_error: 0.1755\n",
      "Epoch 11/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0859 - root_mean_squared_error: 0.2069 - val_loss: 0.0626 - val_root_mean_squared_error: 0.1803\n",
      "Epoch 12/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0848 - root_mean_squared_error: 0.2061 - val_loss: 0.0596 - val_root_mean_squared_error: 0.1761\n",
      "Epoch 13/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0834 - root_mean_squared_error: 0.2051 - val_loss: 0.0584 - val_root_mean_squared_error: 0.1727\n",
      "Epoch 14/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0822 - root_mean_squared_error: 0.2043 - val_loss: 0.0585 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 15/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0811 - root_mean_squared_error: 0.2035 - val_loss: 0.0573 - val_root_mean_squared_error: 0.1738\n",
      "Epoch 16/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0804 - root_mean_squared_error: 0.2031 - val_loss: 0.0545 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 17/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0795 - root_mean_squared_error: 0.2023 - val_loss: 0.0590 - val_root_mean_squared_error: 0.1760\n",
      "Epoch 18/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0785 - root_mean_squared_error: 0.2017 - val_loss: 0.0568 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 19/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0782 - root_mean_squared_error: 0.2016 - val_loss: 0.0554 - val_root_mean_squared_error: 0.1691\n",
      "Epoch 20/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0776 - root_mean_squared_error: 0.2011 - val_loss: 0.0596 - val_root_mean_squared_error: 0.1809\n",
      "Epoch 21/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0772 - root_mean_squared_error: 0.2009 - val_loss: 0.0574 - val_root_mean_squared_error: 0.1805\n",
      "Epoch 22/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0766 - root_mean_squared_error: 0.2005 - val_loss: 0.0556 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 23/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0763 - root_mean_squared_error: 0.2005 - val_loss: 0.0557 - val_root_mean_squared_error: 0.1700\n",
      "Epoch 24/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0759 - root_mean_squared_error: 0.2001 - val_loss: 0.0541 - val_root_mean_squared_error: 0.1689\n",
      "Epoch 25/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0754 - root_mean_squared_error: 0.1998 - val_loss: 0.0536 - val_root_mean_squared_error: 0.1685\n",
      "Epoch 26/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0753 - root_mean_squared_error: 0.1998 - val_loss: 0.0603 - val_root_mean_squared_error: 0.1798\n",
      "Epoch 27/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0752 - root_mean_squared_error: 0.1998 - val_loss: 0.0588 - val_root_mean_squared_error: 0.1792\n",
      "Epoch 28/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0746 - root_mean_squared_error: 0.1994 - val_loss: 0.0538 - val_root_mean_squared_error: 0.1699\n",
      "Epoch 29/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0744 - root_mean_squared_error: 0.1995 - val_loss: 0.0542 - val_root_mean_squared_error: 0.1721\n",
      "Epoch 30/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0741 - root_mean_squared_error: 0.1991 - val_loss: 0.0601 - val_root_mean_squared_error: 0.1831\n",
      "Epoch 31/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0738 - root_mean_squared_error: 0.1988 - val_loss: 0.0560 - val_root_mean_squared_error: 0.1761\n",
      "Epoch 32/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0735 - root_mean_squared_error: 0.1985 - val_loss: 0.0529 - val_root_mean_squared_error: 0.1678\n",
      "Epoch 33/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0737 - root_mean_squared_error: 0.1987 - val_loss: 0.0554 - val_root_mean_squared_error: 0.1723\n",
      "Epoch 34/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0733 - root_mean_squared_error: 0.1983 - val_loss: 0.0547 - val_root_mean_squared_error: 0.1738\n",
      "Epoch 35/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0732 - root_mean_squared_error: 0.1982 - val_loss: 0.0541 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 36/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0729 - root_mean_squared_error: 0.1981 - val_loss: 0.0544 - val_root_mean_squared_error: 0.1759\n",
      "Epoch 37/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0726 - root_mean_squared_error: 0.1977 - val_loss: 0.0545 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 38/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0722 - root_mean_squared_error: 0.1975 - val_loss: 0.0581 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 39/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0721 - root_mean_squared_error: 0.1971 - val_loss: 0.0518 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 40/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0721 - root_mean_squared_error: 0.1972 - val_loss: 0.0535 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 41/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0721 - root_mean_squared_error: 0.1970 - val_loss: 0.0515 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 42/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0719 - root_mean_squared_error: 0.1970 - val_loss: 0.0545 - val_root_mean_squared_error: 0.1719\n",
      "Epoch 43/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0720 - root_mean_squared_error: 0.1970 - val_loss: 0.0533 - val_root_mean_squared_error: 0.1719\n",
      "Epoch 44/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0713 - root_mean_squared_error: 0.1963 - val_loss: 0.0526 - val_root_mean_squared_error: 0.1703\n",
      "Epoch 45/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0717 - root_mean_squared_error: 0.1970 - val_loss: 0.0522 - val_root_mean_squared_error: 0.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0718 - root_mean_squared_error: 0.1970 - val_loss: 0.0531 - val_root_mean_squared_error: 0.1695\n",
      "Epoch 47/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0711 - root_mean_squared_error: 0.1964 - val_loss: 0.0565 - val_root_mean_squared_error: 0.1793\n",
      "Epoch 48/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0709 - root_mean_squared_error: 0.1961 - val_loss: 0.0501 - val_root_mean_squared_error: 0.1644\n",
      "Epoch 49/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0709 - root_mean_squared_error: 0.1960 - val_loss: 0.0595 - val_root_mean_squared_error: 0.1837\n",
      "Epoch 50/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0709 - root_mean_squared_error: 0.1960 - val_loss: 0.0541 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 51/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0708 - root_mean_squared_error: 0.1961 - val_loss: 0.0537 - val_root_mean_squared_error: 0.1731\n",
      "Epoch 52/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0704 - root_mean_squared_error: 0.1954 - val_loss: 0.0536 - val_root_mean_squared_error: 0.1724\n",
      "Epoch 53/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0703 - root_mean_squared_error: 0.1953 - val_loss: 0.0538 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 54/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0704 - root_mean_squared_error: 0.1951 - val_loss: 0.0520 - val_root_mean_squared_error: 0.1701\n",
      "Epoch 55/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0699 - root_mean_squared_error: 0.1947 - val_loss: 0.0483 - val_root_mean_squared_error: 0.1620\n",
      "Epoch 56/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0697 - root_mean_squared_error: 0.1943 - val_loss: 0.0544 - val_root_mean_squared_error: 0.1717 0s - loss: 0.0700 - root_mean_squared_erro\n",
      "Epoch 57/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0701 - root_mean_squared_error: 0.1949 - val_loss: 0.0515 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 58/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0697 - root_mean_squared_error: 0.1944 - val_loss: 0.0523 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 59/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0696 - root_mean_squared_error: 0.1945 - val_loss: 0.0514 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 60/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0696 - root_mean_squared_error: 0.1945 - val_loss: 0.0524 - val_root_mean_squared_error: 0.1693\n",
      "Epoch 61/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0695 - root_mean_squared_error: 0.1942 - val_loss: 0.0522 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 62/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0691 - root_mean_squared_error: 0.1937 - val_loss: 0.0559 - val_root_mean_squared_error: 0.1739\n",
      "Epoch 63/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0691 - root_mean_squared_error: 0.1939 - val_loss: 0.0542 - val_root_mean_squared_error: 0.1758\n",
      "Epoch 64/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0689 - root_mean_squared_error: 0.1935 - val_loss: 0.0539 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 65/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0694 - root_mean_squared_error: 0.1942 - val_loss: 0.0543 - val_root_mean_squared_error: 0.1733\n",
      "Epoch 66/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0690 - root_mean_squared_error: 0.1938 - val_loss: 0.0545 - val_root_mean_squared_error: 0.1732\n",
      "Epoch 67/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0688 - root_mean_squared_error: 0.1936 - val_loss: 0.0503 - val_root_mean_squared_error: 0.1660\n",
      "Epoch 68/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0686 - root_mean_squared_error: 0.1934 - val_loss: 0.0552 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 69/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0689 - root_mean_squared_error: 0.1935 - val_loss: 0.0495 - val_root_mean_squared_error: 0.1655\n",
      "Epoch 70/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0686 - root_mean_squared_error: 0.1935 - val_loss: 0.0542 - val_root_mean_squared_error: 0.1752\n",
      "Epoch 71/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0689 - root_mean_squared_error: 0.1937 - val_loss: 0.0538 - val_root_mean_squared_error: 0.1718\n",
      "Epoch 72/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0683 - root_mean_squared_error: 0.1927 - val_loss: 0.0527 - val_root_mean_squared_error: 0.1691\n",
      "Epoch 73/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0683 - root_mean_squared_error: 0.1925 - val_loss: 0.0557 - val_root_mean_squared_error: 0.1799\n",
      "Epoch 74/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0680 - root_mean_squared_error: 0.1923 - val_loss: 0.0543 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 75/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0684 - root_mean_squared_error: 0.1928 - val_loss: 0.0518 - val_root_mean_squared_error: 0.1685\n",
      "Epoch 76/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0681 - root_mean_squared_error: 0.1922 - val_loss: 0.0538 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 77/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0681 - root_mean_squared_error: 0.1923 - val_loss: 0.0512 - val_root_mean_squared_error: 0.1693\n",
      "Epoch 78/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0680 - root_mean_squared_error: 0.1921 - val_loss: 0.0528 - val_root_mean_squared_error: 0.1737\n",
      "Epoch 79/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0679 - root_mean_squared_error: 0.1921 - val_loss: 0.0514 - val_root_mean_squared_error: 0.1661\n",
      "Epoch 80/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0677 - root_mean_squared_error: 0.1918 - val_loss: 0.0531 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 81/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0678 - root_mean_squared_error: 0.1917 - val_loss: 0.0496 - val_root_mean_squared_error: 0.1686\n",
      "Epoch 82/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0678 - root_mean_squared_error: 0.1916 - val_loss: 0.0529 - val_root_mean_squared_error: 0.1718\n",
      "Epoch 83/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0678 - root_mean_squared_error: 0.1917 - val_loss: 0.0531 - val_root_mean_squared_error: 0.1720\n",
      "Epoch 84/1000\n",
      "450000/450000 [==============================] - ETA: 0s - loss: 0.0678 - root_mean_squared_error: 0.191 - ETA: 0s - loss: 0.0678 - root_mean_squared_error: 0.191 - 1s 2us/step - loss: 0.0678 - root_mean_squared_error: 0.1918 - val_loss: 0.0501 - val_root_mean_squared_error: 0.1638\n",
      "Epoch 85/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0677 - root_mean_squared_error: 0.1917 - val_loss: 0.0473 - val_root_mean_squared_error: 0.1597\n",
      "Epoch 86/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0677 - root_mean_squared_error: 0.1918 - val_loss: 0.0497 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 87/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0678 - root_mean_squared_error: 0.1918 - val_loss: 0.0529 - val_root_mean_squared_error: 0.1727\n",
      "Epoch 88/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0676 - root_mean_squared_error: 0.1914 - val_loss: 0.0485 - val_root_mean_squared_error: 0.1680\n",
      "Epoch 89/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0676 - root_mean_squared_error: 0.1917 - val_loss: 0.0520 - val_root_mean_squared_error: 0.1717\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0673 - root_mean_squared_error: 0.1911 - val_loss: 0.0516 - val_root_mean_squared_error: 0.1679\n",
      "Epoch 91/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0674 - root_mean_squared_error: 0.1916 - val_loss: 0.0500 - val_root_mean_squared_error: 0.1640\n",
      "Epoch 92/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0671 - root_mean_squared_error: 0.1912 - val_loss: 0.0486 - val_root_mean_squared_error: 0.1628\n",
      "Epoch 93/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0669 - root_mean_squared_error: 0.1909 - val_loss: 0.0515 - val_root_mean_squared_error: 0.1659\n",
      "Epoch 94/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0669 - root_mean_squared_error: 0.1909 - val_loss: 0.0530 - val_root_mean_squared_error: 0.1727\n",
      "Epoch 95/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0665 - root_mean_squared_error: 0.1902 - val_loss: 0.0564 - val_root_mean_squared_error: 0.1813\n",
      "Epoch 96/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0671 - root_mean_squared_error: 0.1911 - val_loss: 0.0518 - val_root_mean_squared_error: 0.1690\n",
      "Epoch 97/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0667 - root_mean_squared_error: 0.1907 - val_loss: 0.0575 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 98/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0665 - root_mean_squared_error: 0.1906 - val_loss: 0.0527 - val_root_mean_squared_error: 0.1713\n",
      "Epoch 99/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0666 - root_mean_squared_error: 0.1906 - val_loss: 0.0498 - val_root_mean_squared_error: 0.1644\n",
      "Epoch 100/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0664 - root_mean_squared_error: 0.1904 - val_loss: 0.0566 - val_root_mean_squared_error: 0.1807\n",
      "Epoch 101/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0661 - root_mean_squared_error: 0.1901 - val_loss: 0.0530 - val_root_mean_squared_error: 0.1732\n",
      "Epoch 102/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0660 - root_mean_squared_error: 0.1898 - val_loss: 0.0561 - val_root_mean_squared_error: 0.1759\n",
      "Epoch 103/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0663 - root_mean_squared_error: 0.1902 - val_loss: 0.0533 - val_root_mean_squared_error: 0.1711\n",
      "Epoch 104/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0663 - root_mean_squared_error: 0.1903 - val_loss: 0.0534 - val_root_mean_squared_error: 0.1683\n",
      "Epoch 105/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0662 - root_mean_squared_error: 0.1903 - val_loss: 0.0509 - val_root_mean_squared_error: 0.1678\n",
      "Epoch 106/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0663 - root_mean_squared_error: 0.1901 - val_loss: 0.0493 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 107/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1897 - val_loss: 0.0517 - val_root_mean_squared_error: 0.1674\n",
      "Epoch 108/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0663 - root_mean_squared_error: 0.1901 - val_loss: 0.0547 - val_root_mean_squared_error: 0.1745\n",
      "Epoch 109/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0662 - root_mean_squared_error: 0.1903 - val_loss: 0.0480 - val_root_mean_squared_error: 0.1619\n",
      "Epoch 110/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0661 - root_mean_squared_error: 0.1902 - val_loss: 0.0525 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 111/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0661 - root_mean_squared_error: 0.1901 - val_loss: 0.0557 - val_root_mean_squared_error: 0.1799\n",
      "Epoch 112/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0661 - root_mean_squared_error: 0.1902 - val_loss: 0.0557 - val_root_mean_squared_error: 0.1786\n",
      "Epoch 113/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0660 - root_mean_squared_error: 0.1897 - val_loss: 0.0520 - val_root_mean_squared_error: 0.1708\n",
      "Epoch 114/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0663 - root_mean_squared_error: 0.1903 - val_loss: 0.0541 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 115/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1899 - val_loss: 0.0525 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 116/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0661 - root_mean_squared_error: 0.1903 - val_loss: 0.0504 - val_root_mean_squared_error: 0.1670\n",
      "Epoch 117/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0663 - root_mean_squared_error: 0.1901 - val_loss: 0.0537 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 118/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1901 - val_loss: 0.0493 - val_root_mean_squared_error: 0.1634\n",
      "Epoch 119/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0663 - root_mean_squared_error: 0.1903 - val_loss: 0.0562 - val_root_mean_squared_error: 0.1770\n",
      "Epoch 120/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0661 - root_mean_squared_error: 0.1902 - val_loss: 0.0543 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 121/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0660 - root_mean_squared_error: 0.1901 - val_loss: 0.0558 - val_root_mean_squared_error: 0.1748\n",
      "Epoch 122/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1898 - val_loss: 0.0526 - val_root_mean_squared_error: 0.1680\n",
      "Epoch 123/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1899 - val_loss: 0.0511 - val_root_mean_squared_error: 0.1693\n",
      "Epoch 124/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0660 - root_mean_squared_error: 0.1900 - val_loss: 0.0538 - val_root_mean_squared_error: 0.1736\n",
      "Epoch 125/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0661 - root_mean_squared_error: 0.1901 - val_loss: 0.0519 - val_root_mean_squared_error: 0.1672\n",
      "Epoch 126/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0661 - root_mean_squared_error: 0.1902 - val_loss: 0.0519 - val_root_mean_squared_error: 0.1701\n",
      "Epoch 127/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1897 - val_loss: 0.0498 - val_root_mean_squared_error: 0.1655\n",
      "Epoch 128/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1897 - val_loss: 0.0487 - val_root_mean_squared_error: 0.1625\n",
      "Epoch 129/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0662 - root_mean_squared_error: 0.1901 - val_loss: 0.0520 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 130/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0656 - root_mean_squared_error: 0.1897 - val_loss: 0.0512 - val_root_mean_squared_error: 0.1731\n",
      "Epoch 131/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1896 - val_loss: 0.0521 - val_root_mean_squared_error: 0.1690\n",
      "Epoch 132/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0660 - root_mean_squared_error: 0.1899 - val_loss: 0.0511 - val_root_mean_squared_error: 0.1650\n",
      "Epoch 133/1000\n",
      "450000/450000 [==============================] - ETA: 0s - loss: 0.0659 - root_mean_squared_error: 0.189 - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1898 - val_loss: 0.0540 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 134/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0663 - root_mean_squared_error: 0.1904 - val_loss: 0.0540 - val_root_mean_squared_error: 0.1807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1897 - val_loss: 0.0531 - val_root_mean_squared_error: 0.1713\n",
      "Epoch 136/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1896 - val_loss: 0.0516 - val_root_mean_squared_error: 0.1664\n",
      "Epoch 137/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1900 - val_loss: 0.0527 - val_root_mean_squared_error: 0.1702\n",
      "Epoch 138/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1899 - val_loss: 0.0540 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 139/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1899 - val_loss: 0.0562 - val_root_mean_squared_error: 0.1730\n",
      "Epoch 140/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0656 - root_mean_squared_error: 0.1896 - val_loss: 0.0488 - val_root_mean_squared_error: 0.1663\n",
      "Epoch 141/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1899 - val_loss: 0.0480 - val_root_mean_squared_error: 0.1611\n",
      "Epoch 142/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1896 - val_loss: 0.0525 - val_root_mean_squared_error: 0.1704\n",
      "Epoch 143/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1898 - val_loss: 0.0475 - val_root_mean_squared_error: 0.1621\n",
      "Epoch 144/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1897 - val_loss: 0.0508 - val_root_mean_squared_error: 0.1684\n",
      "Epoch 145/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1895 - val_loss: 0.0527 - val_root_mean_squared_error: 0.1739\n",
      "Epoch 146/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0660 - root_mean_squared_error: 0.1901 - val_loss: 0.0532 - val_root_mean_squared_error: 0.1684\n",
      "Epoch 147/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1896 - val_loss: 0.0510 - val_root_mean_squared_error: 0.1690\n",
      "Epoch 148/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1896 - val_loss: 0.0489 - val_root_mean_squared_error: 0.1671\n",
      "Epoch 149/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1898 - val_loss: 0.0513 - val_root_mean_squared_error: 0.1679\n",
      "Epoch 150/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1897 - val_loss: 0.0542 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 151/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0656 - root_mean_squared_error: 0.1895 - val_loss: 0.0536 - val_root_mean_squared_error: 0.1721 - loss: 0.0656 - root_mean_squared_error: 0.189\n",
      "Epoch 152/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1898 - val_loss: 0.0541 - val_root_mean_squared_error: 0.1723\n",
      "Epoch 153/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0654 - root_mean_squared_error: 0.1895 - val_loss: 0.0541 - val_root_mean_squared_error: 0.1778\n",
      "Epoch 154/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0656 - root_mean_squared_error: 0.1895 - val_loss: 0.0518 - val_root_mean_squared_error: 0.1670\n",
      "Epoch 155/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0656 - root_mean_squared_error: 0.1895 - val_loss: 0.0512 - val_root_mean_squared_error: 0.1682\n",
      "Epoch 156/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1899 - val_loss: 0.0503 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 157/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0656 - root_mean_squared_error: 0.1895 - val_loss: 0.0553 - val_root_mean_squared_error: 0.1784\n",
      "Epoch 158/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1892 - val_loss: 0.0492 - val_root_mean_squared_error: 0.1664\n",
      "Epoch 159/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1901 - val_loss: 0.0524 - val_root_mean_squared_error: 0.1720\n",
      "Epoch 160/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1899 - val_loss: 0.0532 - val_root_mean_squared_error: 0.1757\n",
      "Epoch 161/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1900 - val_loss: 0.0553 - val_root_mean_squared_error: 0.1815\n",
      "Epoch 162/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1897 - val_loss: 0.0544 - val_root_mean_squared_error: 0.1730\n",
      "Epoch 163/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0653 - root_mean_squared_error: 0.1894 - val_loss: 0.0527 - val_root_mean_squared_error: 0.1701\n",
      "Epoch 164/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1897 - val_loss: 0.0524 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 165/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1899 - val_loss: 0.0501 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 166/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1900 - val_loss: 0.0519 - val_root_mean_squared_error: 0.1748\n",
      "Epoch 167/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1898 - val_loss: 0.0536 - val_root_mean_squared_error: 0.1718\n",
      "Epoch 168/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1897 - val_loss: 0.0508 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 169/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0654 - root_mean_squared_error: 0.1896 - val_loss: 0.0500 - val_root_mean_squared_error: 0.1641\n",
      "Epoch 170/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0659 - root_mean_squared_error: 0.1901 - val_loss: 0.0507 - val_root_mean_squared_error: 0.1702\n",
      "Epoch 171/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1897 - val_loss: 0.0592 - val_root_mean_squared_error: 0.1835\n",
      "Epoch 172/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0654 - root_mean_squared_error: 0.1893 - val_loss: 0.0480 - val_root_mean_squared_error: 0.1611\n",
      "Epoch 173/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1898 - val_loss: 0.0514 - val_root_mean_squared_error: 0.1706\n",
      "Epoch 174/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1897 - val_loss: 0.0532 - val_root_mean_squared_error: 0.1745\n",
      "Epoch 175/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1898 - val_loss: 0.0556 - val_root_mean_squared_error: 0.1730\n",
      "Epoch 176/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1901 - val_loss: 0.0502 - val_root_mean_squared_error: 0.1675\n",
      "Epoch 177/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0660 - root_mean_squared_error: 0.1900 - val_loss: 0.0542 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 178/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0656 - root_mean_squared_error: 0.1898 - val_loss: 0.0495 - val_root_mean_squared_error: 0.1649\n",
      "Epoch 179/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0660 - root_mean_squared_error: 0.1902 - val_loss: 0.0506 - val_root_mean_squared_error: 0.1654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0658 - root_mean_squared_error: 0.1900 - val_loss: 0.0524 - val_root_mean_squared_error: 0.1683\n",
      "Epoch 181/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1895 - val_loss: 0.0488 - val_root_mean_squared_error: 0.1629\n",
      "Epoch 182/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1895 - val_loss: 0.0533 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 183/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0657 - root_mean_squared_error: 0.1896 - val_loss: 0.0541 - val_root_mean_squared_error: 0.1730\n",
      "Epoch 184/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0655 - root_mean_squared_error: 0.1897 - val_loss: 0.0504 - val_root_mean_squared_error: 0.1649\n",
      "Epoch 185/1000\n",
      "450000/450000 [==============================] - 1s 2us/step - loss: 0.0656 - root_mean_squared_error: 0.1897 - val_loss: 0.0547 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 00185: early stopping\n",
      "0.04432658076286316 0.16668744385242462\n",
      "iter: 0 nL: 2 nN: 15 trsize: 600000 TestRMSE: 0.16668744385242462\n"
     ]
    }
   ],
   "source": [
    "# Main Function\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # List of optimizers to choose from    \n",
    "    optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "    optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "    \n",
    "    # selecting the optimizer\n",
    "    optimizer_num = 2\n",
    "    optimizer_name = optimizer_names[optimizer_num]\n",
    "    optimizer_val = optimizer_vals[optimizer_num]\n",
    "    \n",
    "    # Selecting Other Hyper-parameters\n",
    "    drop_rate = 0.1 # Fraction of nodes to be dropped out\n",
    "    n_layers = 2 # Number of hidden layers\n",
    "    n_nodes = 15 # Number of nodes per hidden layer\n",
    "\n",
    "    # Iterating over different training fractions and splitting indices for train-test splits\n",
    "#     trsize_range = [1500,20,15,10,5]\n",
    "#     trsize_range = [24]\n",
    "#     trsize_range = [1303]\n",
    "    trsize_range = [600000]\n",
    "    \n",
    "    iter_range = np.arange(1) # range of iteration numbers for random initialization of NN parameters\n",
    "    tr_size = trsize_range[0]\n",
    "    \n",
    "    #List of lakes to choose from\n",
    "    lake = ['mendota' , 'mille_lacs']\n",
    "    lake_num = 0  # 0 : mendota , 1 : mille_lacs\n",
    "    lake_name = lake[lake_num]\n",
    "    \n",
    "    use_YPhy  = 0\n",
    "    \n",
    "    # iterating through all possible params\n",
    "    for iteration in iter_range:\n",
    "        results, result_file = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                        iteration, n_layers, n_nodes, tr_size, lake_name, use_YPhy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading unsupervised data\n",
    "# data_dir = '../../data/'\n",
    "# unsup_filename = 'mendota' + '_sampled.mat'\n",
    "# unsup_mat = spio.loadmat(data_dir+unsup_filename, squeeze_me=True,\n",
    "# variable_names=['Xc_doy1','Xc_doy2'])\n",
    "\n",
    "# uX1 = unsup_mat['Xc_doy1'] # Xc at depth i for every pair of consecutive depth values\n",
    "# uY1 = uX1[:,-1]\n",
    "# uX1 = uX1[:,:-1]\n",
    "\n",
    "# pd.DataFrame(uX1)[4].unique().shape\n",
    "\n",
    "# pd.DataFrame(uX1).iloc[:150,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load(model_name)\n",
    "# prediction = model.predict(np.array(tk.texts_to_sequences(text)))\n",
    "# print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict keys are: \n",
      "['train_rmse', 'val_rmse', 'test_rmse']\n",
      "Test RMSE:  0.20168207585811615\n"
     ]
    }
   ],
   "source": [
    "dict_keys = []\n",
    "\n",
    "# get key and value \n",
    "print (\"Dict keys are: \") \n",
    "for key, value in results.items(): \n",
    "    dict_keys.append(key)\n",
    "\n",
    "print(dict_keys)\n",
    "train_rmse = results[dict_keys[0]]\n",
    "val_rmse = results[dict_keys[1]]\n",
    "test_rmse = results[dict_keys[2]]\n",
    "print(\"Test RMSE: \",test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(train_rmse)\n",
    "plt.plot(val_rmse)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
