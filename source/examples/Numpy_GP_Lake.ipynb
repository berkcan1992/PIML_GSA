{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from numpy.linalg import cholesky, det, lstsq\n",
    "from scipy.optimize import minimize\n",
    "import scipy.spatial.distance as spdist\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.io as spio\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def pass_arg(nsim, tr_size):\n",
    "\n",
    "    # Compute the RMSE\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred-y_true)**2))\n",
    "    \n",
    "    print(\"tr_Size:\",tr_size)\n",
    "    \n",
    "    #List of lakes to choose from\n",
    "    lake = ['mendota' , 'mille_lacs']\n",
    "    lake_num = 0  # 0 : mendota , 1 : mille_lacs\n",
    "    lake_name = lake[lake_num]\n",
    "\n",
    "    # Load features (Xc) and target values (Y)\n",
    "    data_dir = '../../data/'\n",
    "    filename = lake_name + '.mat'\n",
    "    mat = spio.loadmat(data_dir + filename, squeeze_me=True,\n",
    "    variable_names=['Y','Xc_doy','Modeled_temp'])\n",
    "    Xc = mat['Xc_doy']\n",
    "    Y = mat['Y']\n",
    "        \n",
    "    # train and test data\n",
    "    trainX, trainY = Xc[:tr_size,:-1], Y[:tr_size]\n",
    "    testX, testY = Xc[-50:,:-1], Y[-50:]\n",
    "        \n",
    "    def covSEard(hyp=None, x=None, z=None):\n",
    "        ''' Squared Exponential covariance function with Automatic Relevance Detemination\n",
    "         (ARD) distance measure. The covariance function is parameterized as:\n",
    "\n",
    "         k(x^p,x^q) = sf2 * exp(-(x^p - x^q)' * inv(P) * (x^p - x^q)/2)\n",
    "\n",
    "         where the P matrix is diagonal with ARD parameters ell_1^2,...,ell_D^2, where\n",
    "         D is the dimension of the input space and sf2 is the signal variance.\n",
    "\n",
    "         The hyperparameters are:\n",
    "\n",
    "         hyp = [ log(ell_1)\n",
    "                 log(ell_2)\n",
    "                 ...\n",
    "                 log(ell_D)\n",
    "                 log(sqrt(sf2)) ]\n",
    "        '''\n",
    "\n",
    "#         [n, D] = x.shape\n",
    "#         ell = 1/np.array(hyp[0:D])        # characteristic length scale\n",
    "        \n",
    "        \n",
    "#         sf2 = np.array(hyp[D])**2         # signal variance\n",
    "#         tmp = np.dot(np.diag(ell),x.T).T\n",
    "#         A = spdist.cdist(np.dot(np.diag(ell),x.T).T, np.dot(np.diag(ell),z.T).T, 'sqeuclidean') # cross covariances\n",
    "\n",
    "#         A = sf2*np.exp(-0.5*A)  \n",
    "\n",
    "        [n, D] = x.shape\n",
    "        ell = 1/np.array(hyp)[0,0:D]        # characteristic length scale\n",
    "        \n",
    "        sf2 = np.array(hyp)[0,D]**2         # signal variance\n",
    "        A = spdist.cdist(np.dot(np.diag(ell),x.T).T, np.dot(np.diag(ell),z.T).T, 'sqeuclidean') # cross covariances\n",
    "        A = sf2*np.exp(-0.5*A)\n",
    "        return A\n",
    "\n",
    "\n",
    "    def posterior_predictive(X_s, X_train, Y_train, *args):\n",
    "        '''  \n",
    "        Computes the suffifient statistics of the GP posterior predictive distribution \n",
    "        from m training data X_train and Y_train and n new inputs X_s.\n",
    "\n",
    "        Args:\n",
    "            X_s: New input locations (n x d).\n",
    "            X_train: Training locations (m x d).\n",
    "            Y_train: Training targets (m x 1).\n",
    "            l: Kernel length parameter.\n",
    "            sigma_f: Kernel vertical variation parameter.\n",
    "            sigma_y: Noise parameter.\n",
    "\n",
    "        Returns:\n",
    "            Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "        '''\n",
    "        \n",
    "        l = np.array(args)\n",
    "        noise=l[-1]\n",
    "        K = covSEard(hyp=[l[:-1]], x=X_train, z=X_train) + noise**2 * np.eye(len(X_train))\n",
    "        K_s = covSEard(hyp=[l[:-1]], x=X_train, z=X_s)\n",
    "        K_ss = covSEard(hyp=[l[:-1]], x=X_s, z=X_s)  + 1e-8 * np.eye(len(X_s))\n",
    "#         K_inv = inv(K)\n",
    "        K_inv = np.linalg.pinv(K)\n",
    "    \n",
    "        # Equation (4)\n",
    "        mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
    "\n",
    "        # Equation (5)\n",
    "        cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "        \n",
    "        return mu_s, cov_s\n",
    "\n",
    "\n",
    "    def nll_fn(X_train, Y_train, noise=0, naive=False):\n",
    "        '''\n",
    "        Returns a function that computes the negative log marginal\n",
    "        likelihood for training data X_train and Y_train and given \n",
    "        noise level.\n",
    "\n",
    "        Args:\n",
    "            X_train: training locations (m x d).\n",
    "            Y_train: training targets (m x 1).\n",
    "            noise: known noise level of Y_train.\n",
    "            naive: if True use a naive implementation of Eq. (7), if \n",
    "                   False use a numerically more stable implementation. \n",
    "\n",
    "        Returns:\n",
    "            Minimization objective.\n",
    "        '''\n",
    "\n",
    "        def nll_stable(theta):\n",
    "            # Numerically more stable implementation of Eq. (7) as described\n",
    "            # in http://www.gaussianprocess.org/gpml/chapters/RW2.pdf, Section\n",
    "            # 2.2, Algorithm 2.1.\n",
    "            K = covSEard(hyp=[theta], x=X_train, z=X_train) + \\\n",
    "            theta[-1]**2 * np.eye(len(X_train))\n",
    "            \n",
    "            K += 1e-6 * np.eye(*K.shape)\n",
    "            L = cholesky(K)\n",
    "            return np.sum(np.log(np.diagonal(L))) + \\\n",
    "                   0.5 * Y_train.T.dot(lstsq(L.T, lstsq(L, Y_train, rcond=None)[0], rcond=None)[0]) + \\\n",
    "                   0.5 * len(X_train) * np.log(2*np.pi)\n",
    "\n",
    "        if naive:\n",
    "            return nll_naive\n",
    "        else:\n",
    "            return nll_stable\n",
    "\n",
    "    \n",
    "    # Optimization\n",
    "    res = minimize(nll_fn(trainX, trainY), x0 = 0.1*np.ones(trainX.shape[1]+2), \n",
    "                       bounds=((1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None), (1e-5, None)),\n",
    "                        method='L-BFGS-B')\n",
    "        \n",
    "#     res = minimize(nll_fn(trainX, trainY), x0 = [.1, .1, .1, 1e-3], \n",
    "#                    bounds=((1e-5, None), (1e-5, None), (1e-5, None), (1e-7, None)),\n",
    "#                     method='L-BFGS-B')\n",
    "    \n",
    "#     print(f'After parameter optimization: l1={res.x[0]:.5f} l2={res.x[1]:.5f} sigma_f={res.x[2]:.5f}')\n",
    "#     print(np.exp(res.x[0]),np.exp(res.x[1]), np.exp(res.x[2]))\n",
    "    mu_s, cov_s = posterior_predictive(testX, trainX, trainY, *res.x)\n",
    "    \n",
    "    RMSE = []\n",
    "    for ii in range(int(nsim)):\n",
    "        samples = np.random.multivariate_normal(mu_s.ravel(), cov_s, 1).T\n",
    "        rmse_test = np.sqrt(mean_squared_error(testY, samples))\n",
    "        RMSE.append(rmse_test)\n",
    "#         print(\"RMSE:\", rmse_test)\n",
    "        \n",
    "#         RMSE.append(root_mean_squared_error(testY, samples))\n",
    "#         print(\"RMSE:\", root_mean_squared_error(testY, samples))\n",
    "\n",
    "#     return samples, RMSE\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmses=[]\n",
    "std_rmses=[]\n",
    "for ii in ([500,100,50]):\n",
    "    test_rmse = pass_arg(10, ii)\n",
    "    mean_rmse = np.mean(test_rmse)\n",
    "    std_rmse = np.std(test_rmse)\n",
    "    mean_rmses.append(mean_rmse)\n",
    "    std_rmses.append(std_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "tr_size = 500\n",
    "use_YPhy = 0\n",
    "\n",
    "#List of lakes to choose from\n",
    "lake = ['mendota' , 'mille_lacs']\n",
    "lake_num = 0  # 0 : mendota , 1 : mille_lacs\n",
    "lake_name = lake[lake_num]\n",
    "\n",
    "# Load features (Xc) and target values (Y)\n",
    "data_dir = '../../data/'\n",
    "filename = lake_name + '.mat'\n",
    "mat = spio.loadmat(data_dir + filename, squeeze_me=True,\n",
    "variable_names=['Y','Xc_doy','Modeled_temp'])\n",
    "Xc = mat['Xc_doy']\n",
    "Y = mat['Y']\n",
    "Xc = Xc[:,:-1]\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# Xc = scaler.fit_transform(Xc)\n",
    "\n",
    "# train and test data\n",
    "trainX, testX, trainY, testY = train_test_split(Xc, Y, train_size=tr_size/Xc.shape[0], \n",
    "                                                test_size=tr_size/Xc.shape[0], random_state=42, shuffle=True)\n",
    "\n",
    "# trainX, trainY = Xc[:tr_size,:-1], Y[:tr_size]\n",
    "# testX, testY = Xc[tr_size:tr_size+50,:-1], Y[tr_size:tr_size+50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.019934</td>\n",
       "      <td>-0.580457</td>\n",
       "      <td>0.892478</td>\n",
       "      <td>0.154132</td>\n",
       "      <td>-1.315452</td>\n",
       "      <td>-1.206431</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.902442</td>\n",
       "      <td>0.218041</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.871121</td>\n",
       "      <td>0.351973</td>\n",
       "      <td>-0.651273</td>\n",
       "      <td>-1.680445</td>\n",
       "      <td>-1.737498</td>\n",
       "      <td>-2.141416</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>-0.913915</td>\n",
       "      <td>1.291422</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>2.302617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.707195</td>\n",
       "      <td>-1.534375</td>\n",
       "      <td>1.453842</td>\n",
       "      <td>-1.438538</td>\n",
       "      <td>-1.688852</td>\n",
       "      <td>-2.101777</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>1.512379</td>\n",
       "      <td>-0.088843</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.453645</td>\n",
       "      <td>-0.110562</td>\n",
       "      <td>-0.510932</td>\n",
       "      <td>1.363849</td>\n",
       "      <td>-0.607454</td>\n",
       "      <td>-0.314231</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.101888</td>\n",
       "      <td>-0.560569</td>\n",
       "      <td>-0.290737</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036379</td>\n",
       "      <td>-0.193212</td>\n",
       "      <td>-0.089909</td>\n",
       "      <td>1.262509</td>\n",
       "      <td>0.062501</td>\n",
       "      <td>0.505631</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.404804</td>\n",
       "      <td>0.843964</td>\n",
       "      <td>-0.392426</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.155598</td>\n",
       "      <td>-0.706149</td>\n",
       "      <td>-1.633660</td>\n",
       "      <td>1.431189</td>\n",
       "      <td>0.276018</td>\n",
       "      <td>0.659003</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.219960</td>\n",
       "      <td>-0.267175</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.438743</td>\n",
       "      <td>-0.798475</td>\n",
       "      <td>-0.931955</td>\n",
       "      <td>-0.480360</td>\n",
       "      <td>-0.216351</td>\n",
       "      <td>-0.466446</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.462452</td>\n",
       "      <td>-0.741821</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.380886</td>\n",
       "      <td>-1.063067</td>\n",
       "      <td>-1.493319</td>\n",
       "      <td>0.042995</td>\n",
       "      <td>1.007465</td>\n",
       "      <td>0.611271</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.007980</td>\n",
       "      <td>-0.356746</td>\n",
       "      <td>0.128508</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.157351</td>\n",
       "      <td>0.290198</td>\n",
       "      <td>0.050432</td>\n",
       "      <td>0.185339</td>\n",
       "      <td>0.489955</td>\n",
       "      <td>0.707243</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.138474</td>\n",
       "      <td>-1.328273</td>\n",
       "      <td>-0.007148</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.841106</td>\n",
       "      <td>-1.137394</td>\n",
       "      <td>1.734524</td>\n",
       "      <td>1.167619</td>\n",
       "      <td>-1.077143</td>\n",
       "      <td>-0.010772</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-2.497619</td>\n",
       "      <td>-1.353847</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -1.019934 -0.580457  0.892478  0.154132 -1.315452 -1.206431 -0.267906   \n",
       "1    1.871121  0.351973 -0.651273 -1.680445 -1.737498 -2.141416  3.732374   \n",
       "2    1.707195 -1.534375  1.453842 -1.438538 -1.688852 -2.101777  3.732374   \n",
       "3   -0.453645 -0.110562 -0.510932  1.363849 -0.607454 -0.314231 -0.267906   \n",
       "4   -0.036379 -0.193212 -0.089909  1.262509  0.062501  0.505631 -0.267906   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "495 -0.155598 -0.706149 -1.633660  1.431189  0.276018  0.659003 -0.267906   \n",
       "496 -0.438743 -0.798475 -0.931955 -0.480360 -0.216351 -0.466446 -0.267906   \n",
       "497  0.380886 -1.063067 -1.493319  0.042995  1.007465  0.611271 -0.267906   \n",
       "498  0.157351  0.290198  0.050432  0.185339  0.489955  0.707243 -0.267906   \n",
       "499 -0.841106 -1.137394  1.734524  1.167619 -1.077143 -0.010772 -0.267906   \n",
       "\n",
       "            7         8         9        10  \n",
       "0   -0.902442  0.218041 -0.443125 -0.097724  \n",
       "1   -0.913915  1.291422 -0.443125  2.302617  \n",
       "2    1.512379 -0.088843 -0.443125 -0.097724  \n",
       "3    0.101888 -0.560569 -0.290737 -0.097724  \n",
       "4   -0.404804  0.843964 -0.392426 -0.097724  \n",
       "..        ...       ...       ...       ...  \n",
       "495 -0.219960 -0.267175 -0.443125 -0.097724  \n",
       "496 -0.462452 -0.741821 -0.443125 -0.097724  \n",
       "497  1.007980 -0.356746  0.128508 -0.097724  \n",
       "498 -0.138474 -1.328273 -0.007148 -0.097724  \n",
       "499 -2.497619 -1.353847 -0.443125 -0.097724  \n",
       "\n",
       "[500 rows x 11 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.126004</td>\n",
       "      <td>0.339802</td>\n",
       "      <td>-1.072296</td>\n",
       "      <td>-0.033589</td>\n",
       "      <td>-0.823050</td>\n",
       "      <td>-0.227416</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.430686</td>\n",
       "      <td>0.285957</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.021477</td>\n",
       "      <td>0.194635</td>\n",
       "      <td>1.453842</td>\n",
       "      <td>1.381620</td>\n",
       "      <td>1.204962</td>\n",
       "      <td>1.485757</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.302605</td>\n",
       "      <td>0.648515</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.200305</td>\n",
       "      <td>-0.541765</td>\n",
       "      <td>-0.651273</td>\n",
       "      <td>0.272411</td>\n",
       "      <td>1.538305</td>\n",
       "      <td>1.005846</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.262587</td>\n",
       "      <td>-0.525829</td>\n",
       "      <td>-0.172396</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.468548</td>\n",
       "      <td>0.194635</td>\n",
       "      <td>1.453842</td>\n",
       "      <td>0.934801</td>\n",
       "      <td>-0.773392</td>\n",
       "      <td>-0.709731</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.271699</td>\n",
       "      <td>-0.281245</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.230110</td>\n",
       "      <td>-0.541765</td>\n",
       "      <td>1.032819</td>\n",
       "      <td>1.379368</td>\n",
       "      <td>0.845192</td>\n",
       "      <td>0.964774</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.439747</td>\n",
       "      <td>-0.040784</td>\n",
       "      <td>0.828371</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.677180</td>\n",
       "      <td>1.680927</td>\n",
       "      <td>-0.510932</td>\n",
       "      <td>1.252811</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>0.694663</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.198966</td>\n",
       "      <td>0.186237</td>\n",
       "      <td>-0.337671</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.721887</td>\n",
       "      <td>-1.137394</td>\n",
       "      <td>-0.931955</td>\n",
       "      <td>1.034982</td>\n",
       "      <td>0.666376</td>\n",
       "      <td>0.719408</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.315153</td>\n",
       "      <td>1.353656</td>\n",
       "      <td>-0.240476</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.246765</td>\n",
       "      <td>2.006363</td>\n",
       "      <td>1.032819</td>\n",
       "      <td>1.121993</td>\n",
       "      <td>-0.015915</td>\n",
       "      <td>0.555722</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.619748</td>\n",
       "      <td>-0.004653</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.738543</td>\n",
       "      <td>-1.204883</td>\n",
       "      <td>-0.300421</td>\n",
       "      <td>0.079712</td>\n",
       "      <td>0.865881</td>\n",
       "      <td>0.774355</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.547244</td>\n",
       "      <td>-0.789519</td>\n",
       "      <td>-0.431670</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-1.109348</td>\n",
       "      <td>-0.798475</td>\n",
       "      <td>-0.370591</td>\n",
       "      <td>0.422590</td>\n",
       "      <td>-0.823641</td>\n",
       "      <td>-0.440869</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.588932</td>\n",
       "      <td>-1.518260</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.126004  0.339802 -1.072296 -0.033589 -0.823050 -0.227416 -0.267906   \n",
       "1   -0.021477  0.194635  1.453842  1.381620  1.204962  1.485757 -0.267906   \n",
       "2   -0.200305 -0.541765 -0.651273  0.272411  1.538305  1.005846 -0.267906   \n",
       "3   -0.468548  0.194635  1.453842  0.934801 -0.773392 -0.709731 -0.267906   \n",
       "4   -0.230110 -0.541765  1.032819  1.379368  0.845192  0.964774 -0.267906   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "495 -0.677180  1.680927 -0.510932  1.252811  0.056269  0.694663 -0.267906   \n",
       "496 -0.721887 -1.137394 -0.931955  1.034982  0.666376  0.719408 -0.267906   \n",
       "497  0.246765  2.006363  1.032819  1.121993 -0.015915  0.555722 -0.267906   \n",
       "498  0.738543 -1.204883 -0.300421  0.079712  0.865881  0.774355 -0.267906   \n",
       "499 -1.109348 -0.798475 -0.370591  0.422590 -0.823641 -0.440869 -0.267906   \n",
       "\n",
       "            7         8         9        10  \n",
       "0   -0.430686  0.285957 -0.443125 -0.097724  \n",
       "1    0.302605  0.648515 -0.443125 -0.097724  \n",
       "2    1.262587 -0.525829 -0.172396 -0.097724  \n",
       "3    0.002175  0.271699 -0.281245 -0.097724  \n",
       "4    0.439747 -0.040784  0.828371 -0.097724  \n",
       "..        ...       ...       ...       ...  \n",
       "495 -1.198966  0.186237 -0.337671 -0.097724  \n",
       "496 -0.315153  1.353656 -0.240476 -0.097724  \n",
       "497 -1.619748 -0.004653 -0.443125 -0.097724  \n",
       "498  0.547244 -0.789519 -0.431670 -0.097724  \n",
       "499 -0.588932 -1.518260 -0.443125 -0.097724  \n",
       "\n",
       "[500 rows x 11 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "kernel = C(5.0, (0.5, 1e1)) * RBF(length_scale = [1] * trainX.shape[1], length_scale_bounds=(1e-1, 1e7))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha =1.5, n_restarts_optimizer=5)\n",
    "gp.fit(trainX, trainY)\n",
    "y_pred1, sigma1 = gp.predict(testX, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.16**2 * RBF(length_scale=[0.933, 10.7, 1.11, 12.7, 4.34e+03, 4.4, 22.1, 4.12e+03, 16, 6.44e+03, 5.76e+04])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586860920301515"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.score(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324753821297647"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predTr, sigma_tr = gp.predict(trainX, return_std=True)\n",
    "# y_predTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp.sample_y(trainX, n_samples=int(10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_size = 500\n",
    "\n",
    "# train and test data\n",
    "trainX, trainY = Xc[:tr_size,:-1], Y[:tr_size]\n",
    "testX, testY = Xc[-50:,:-1], Y[-50:]\n",
    "# kernel = C(1.0, (1e-6, 5)) * RBF(length_scale = [0.389, 0.144, 0.189, 2.94, 3.69, 2.34e+03, 1.63e+04, 3.95, 5.12, 5.23, 1.57e+03], length_scale_bounds=(1e-3, 1e5))\n",
    "# kernel = C(10.0, (1e-1, 1e3)) * RBF(length_scale = [0.956, 182, 0.254, 27.6, 986, 28.2, 0.0224, 6.86, 6.27, 3.33, 36.1], length_scale_bounds=(1e-2, 1e5))\n",
    "# kernel = C(1.0, (1e-1, 1e2)) * RBF(length_scale = [0.626, 3.29e+04, 0.0124, 2.95, 5.3, 1.63e+03, 1.42e+03, 4.94, 5.72, 17.7, 0.84], length_scale_bounds=(1e-2, 1e5))\n",
    "# 6.91**2 ,   0.266, 109, 0.207, 5.45, 6.72, 1e+03, 1e+03, 11, 10.3, 19.7, 60.6\n",
    "kernel = C(10.0, (1e-1, 1e3)) * RBF(length_scale = [1] * trainX.shape[1], length_scale_bounds=(1e-2, 1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, copy_X_train=False)\n",
    "gp.fit(trainX, trainY) #removing reshape results in a different error\n",
    "y_pred, sigma = gp.predict(testX, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.log_marginal_likelihood([6.91, 0.266, 109, 0.207, 5.45, 6.72, 1e+03, 1e+03, 11, 10.3, 19.7, 60.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gp.kernel_.k1, ',',gp.kernel_.k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = np.random.uniform(size=(1, 2))\n",
    "ss, rmse = pass_arg(Xx, 100, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = np.random.uniform(size=(3, 2))\n",
    "ss = pass_arg(Xx, 1, 30)\n",
    "# print(ss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
