{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "import random\n",
    "\n",
    "def pass_arg(nsim, tr_size):\n",
    "    print(\"Tr_size:\", tr_size)\n",
    "    def fix_seeds(seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    #     K.set_session(sess)\n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    ss = 1\n",
    "    fix_seeds(ss)\n",
    "\n",
    "    # MC dropout\n",
    "    class MCDropout(Dropout):\n",
    "        def call(self, inputs, training=None):\n",
    "            return super(MCDropout, self).call(inputs, training=True)\n",
    "\n",
    "\n",
    "    # import pickle\n",
    "\n",
    "    # def save_obj(obj, name):\n",
    "    #     with open(name, 'wb') as f:\n",
    "    #         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "    # # Making sure dimensionless bond length is less than 1\n",
    "    # def bond(bl):\n",
    "    #     return bl-1.0\n",
    "\n",
    "    # Making sure dimensionless bond length is less than 1\n",
    "    def bond(bl):\n",
    "        bln = -bl*(bl<0)\n",
    "        blp = bl*(bl>=1.0) - 1*(bl>=1.0)\n",
    "        return bln+blp\n",
    "\n",
    "    # # Making sure final porosity is less than initial\n",
    "    # def poros(poroi, porof):\n",
    "    # #     porof[porof < 0] = 1-porof[porof < 0]\n",
    "    #     porof[porof < 0] = poroi[0]-porof[porof < 0]\n",
    "    #     print(porof)\n",
    "    #     return porof-poroi\n",
    "\n",
    "    # Making sure final porosity is less than initial\n",
    "    def poros(poroi, porof):\n",
    "        porofn = -porof*(porof<0)\n",
    "        porofp = porof*(porof>=poroi) - poroi*(porof>=poroi)\n",
    "        return porofp+porofn\n",
    "\n",
    "    def strength1(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        corr_bl_sorted = np.sort(bl, axis=-1)  # sorts along first axis (down)\n",
    "        return corr_bl_sorted-bl_sorted\n",
    "\n",
    "    def strength2(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        return sum(bl_sorted[1:]-bl_sorted[:-1]<0)/14\n",
    "\n",
    "    def phy_loss_mean(params):\n",
    "        # useful for cross-checking training\n",
    "        loss1, loss2, loss3, loss4, lam1, lam2 = params\n",
    "        x1, x2, x3 = loss1*(loss1>0), loss2*(loss2>0), loss3*(loss3>0)\n",
    "\n",
    "        if x1.any() and x1.shape[0]>1:\n",
    "            X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "            x1 = X_scaled1\n",
    "        if x2.any() and x2.shape[0]>1:\n",
    "            X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "            x2 = X_scaled2\n",
    "        if x3.any() and x3.shape[0]>1:\n",
    "            X_scaled3 = (x3 - np.min(x3)) / (np.max(x3) - np.min(x3))\n",
    "            x3 = X_scaled3\n",
    "        return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3))\n",
    "    #     return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3) + lam2*loss4)\n",
    "\n",
    "    def PGNN_train_test(optimizer_name, optimizer_val, pre_train, tr_size, lamda, iteration, n_nodes, n_layers, drop_frac, reg, samp):\n",
    "\n",
    "        # Hyper-parameters of the training process\n",
    "    #     batch_size = int(tr_size/2)\n",
    "        batch_size = 1\n",
    "        num_epochs = 50\n",
    "        val_frac = 0.2\n",
    "        patience_val = 50\n",
    "\n",
    "        # Initializing results filename\n",
    "        exp_name = \"DNN_pre_hyb_\" + pre_train + optimizer_name + '_trsize' + str(tr_size) + '_lamda' + str(lamda) + '_iter' + str(iteration)\n",
    "        exp_name = exp_name.replace('.','pt')\n",
    "        results_dir = '../results/'\n",
    "        model_name = results_dir + exp_name + '_NoPhyInfomodel.h5' # storing the trained model\n",
    "        if reg==True and samp==25:\n",
    "            results_name = results_dir + exp_name + '_results_25_regularizer.dat' # storing the results of the model\n",
    "        elif reg==False and samp==25:\n",
    "            results_name = results_dir + exp_name + '_results_25.dat' # storing the results of the model\n",
    "        elif reg==True and samp==1519:\n",
    "            results_name = results_dir + exp_name + '_results_1519_regularizer.dat' # storing the results of the model\n",
    "        elif reg==False and samp==1519:\n",
    "            results_name = results_dir + exp_name + '_results_1519.dat' # storing the results of the model\n",
    "        \n",
    "        # Load labeled data\n",
    "        data = np.loadtxt('../data/labeled_data.dat')\n",
    "        x_label = data[:, :-3] # -2 because we do not need porosity predictions\n",
    "        x_labeled = np.hstack((x_label[:,:2],x_label[:,-2:]))\n",
    "        y_labeled = data[:, -3:-1]\n",
    "\n",
    "#         if samp==25:\n",
    "#             data2 = np.loadtxt('../data/unlabeled_data_BK_constw_v2_25.dat')\n",
    "#             x_unlabeled = data2[:, :]\n",
    "#         elif samp==1519:\n",
    "#             data2 = np.loadtxt('../data/unlabeled_data_BK_constw_v2_1525.dat')\n",
    "\n",
    "#         data1 = data2[:1303, :]\n",
    "#         data2 = data2[-6:, :]\n",
    "#         datah = np.vstack((data1,data2))\n",
    "# #         np.random.shuffle(datah)\n",
    "#         x_labeled = np.hstack((datah[:, :2],datah[:,-3:-1]))\n",
    "# #         x_unlabeled = datah[:, :2] # 1303 last regular sample\n",
    "#         y_unlabeled = datah[:, -3:-1]\n",
    "        \n",
    "        # normalize dataset with MinMaxScaler\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range=(0, 1.0))\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "        x_labeled = scaler.fit_transform(x_labeled)\n",
    "#         y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "        # train and test data\n",
    "        trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "    #     testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "    #     init_poro = data[tr_size:, -1]\n",
    "        testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "        init_poro = data[tr_size:, -1]\n",
    "\n",
    "        dependencies = {\n",
    "         'root_mean_squared_error': root_mean_squared_error\n",
    "            }\n",
    "\n",
    "        # load the pre-trained model using non-calibrated physics-based model predictions (./data/unlabeled.dat)\n",
    "        loaded_model = load_model(results_dir + pre_train, custom_objects=dependencies)\n",
    "    \n",
    "        # Creating the model\n",
    "        model = Sequential()\n",
    "        for layer in np.arange(n_layers):\n",
    "            if layer == 0:\n",
    "                model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "            else:\n",
    "                if reg:\n",
    "                    model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=.001, l2=.001)))\n",
    "                else:\n",
    "                    model.add(Dense(n_nodes, activation='relu'))\n",
    "            # model.add(Dropout(rate=drop_frac))\n",
    "            model.add(MCDropout(rate=drop_frac))\n",
    "        model.add(Dense(2, activation='linear'))\n",
    "\n",
    "        # pass the weights to all layers but 1st input layer, whose dimensions are updated\n",
    "        for new_layer, layer in zip(model.layers[1:], loaded_model.layers[1:]):\n",
    "            new_layer.set_weights(layer.get_weights())\n",
    "\n",
    "\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizer_val,\n",
    "                      metrics=[root_mean_squared_error])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val,verbose=1)\n",
    "\n",
    "        print('Running...' + optimizer_name)\n",
    "        history = model.fit(trainX, trainY,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=num_epochs,\n",
    "                            verbose=0,\n",
    "                            validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "\n",
    "        test_score = model.evaluate(testX, testY, verbose=1)\n",
    "        print(test_score)\n",
    "        # predictions = model.predict(testX)\n",
    "    # #     inv_pred = scaler.inverse_transform(predictions)\n",
    "        # phyloss1 = bond(predictions[:,0]) # physics loss 1\n",
    "\n",
    "    # #     init_poro_ndim = np.ones((init_poro.shape))\n",
    "    # #     diff2 = poros(init_poro_ndim, predictions[:,1]) # physics loss 2\n",
    "\n",
    "        # phyloss2 = poros(init_poro, predictions[:,1]) # physics loss 2\n",
    "        # phyloss3 = strength1(predictions[:,0], predictions[:,1])\n",
    "        # phyloss4 = strength2(predictions[:,0], predictions[:,1])\n",
    "\n",
    "        # lam1, lam2 = lamda[0], lamda[1]    \n",
    "        # phyloss = phy_loss_mean([phyloss1, phyloss2, phyloss3, phyloss4, lam1, lam2])\n",
    "\n",
    "        # print('iter: ' + str(iteration) + \n",
    "              # ' nL: ' + str(n_layers) + ' nN: ' + str(n_nodes) + \n",
    "              # ' trsize: ' + str(tr_size) + \n",
    "              # ' TestRMSE: ' + str(test_score[1]) + ' PhyLoss: ' + str(phyloss), \"\\n\")\n",
    "\n",
    "    # #     model.save(model_name)\n",
    "\n",
    "        # # save results\n",
    "        # results = {'train_rmse':history.history['root_mean_squared_error'], \n",
    "                                    # 'val_rmse':history.history['val_root_mean_squared_error'],\n",
    "                                    # 'test_rmse':test_score[1], 'PhyLoss':phyloss}\n",
    "\n",
    "    #     save_obj(results, results_name)\n",
    "\n",
    "        # return results, results_name, predictions, testY, test_score[1]\n",
    "        # predictions = model.predict(Xx)\n",
    "\n",
    "        Xx = np.random.uniform(0,1,(1000,2))\n",
    "        xx1 = np.ones((1000,2))\n",
    "        Xx = np.hstack((Xx,xx1))\n",
    "        \n",
    "        samples = []\n",
    "        for i in range(int(nsim)):\n",
    "#             print(\"simulation num:\",i)\n",
    "            predictions = model.predict(Xx)\n",
    "            predictions = predictions[:,1]\n",
    "            samples.append(predictions)\n",
    "        return np.array(samples)\n",
    "\n",
    "\n",
    "\n",
    "    # Main Function\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        fix_seeds(1)\n",
    "\n",
    "        # List of optimizers to choose from    \n",
    "        optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "        optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "\n",
    "        # selecting the optimizer\n",
    "        optimizer_num = 1\n",
    "        optimizer_name = optimizer_names[optimizer_num]\n",
    "        optimizer_val = optimizer_vals[optimizer_num]\n",
    "\n",
    "        # Selecting Other Hyper-parameters\n",
    "        drop_frac = 0.1 # Fraction of nodes to be dropped out\n",
    "        n_layers = 2 # Number of hidden layers\n",
    "        n_nodes = 5 # Number of nodes per hidden layer\n",
    "\n",
    "        # # Iterating over different training fractions and splitting indices for train-test splits\n",
    "        # trsize_range = [4,6,8,10,20]\n",
    "\n",
    "        # #default training size = 5000\n",
    "        # tr_size = trsize_range[4]\n",
    "\n",
    "        # pre-trained model\n",
    "        pre_train = 'Pre-trainAdadelta_drop0_nL2_nN5_trsize1308_iter0.h5'\n",
    "\n",
    "        tr_size = int(tr_size)\n",
    "\n",
    "        # use regularizer\n",
    "        reg = True\n",
    "\n",
    "        # sample size used\n",
    "        samp = 1519\n",
    "\n",
    "        #set lamda=0 for pgnn0\n",
    "        lamda = [1, 1] # Physics-based regularization constant\n",
    "\n",
    "        # total number of runs\n",
    "        iter_range = np.arange(1)\n",
    "        testrmse=[]\n",
    "        # iterating through all possible params\n",
    "        for iteration in iter_range:\n",
    "            # results, result_file, pred, obs, rmse = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                            # iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "            # testrmse.append(rmse)\n",
    "            pred = PGNN_train_test(optimizer_name, optimizer_val, \n",
    "                                               pre_train, tr_size, lamda, iteration, n_nodes, n_layers, drop_frac, reg, samp)\n",
    "    \n",
    "    return np.squeeze(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr_size: 20\n",
      "Running...Adadelta\n",
      "19/19 [==============================] - 0s 0us/step\n",
      "[0.023258505389094353, 0.12065480649471283]\n"
     ]
    }
   ],
   "source": [
    "pred = pass_arg(50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.89099729e-02,  4.56886850e-02,  5.73223494e-02,  7.05320295e-03,\n",
       "       -1.96643895e-03,  8.31002742e-02, -1.77726001e-02, -2.36039311e-02,\n",
       "        5.57586513e-02,  3.94415669e-02,  1.80524830e-02, -1.71953421e-02,\n",
       "       -8.55147652e-03, -4.63574938e-03, -1.48619032e-02,  4.23643216e-02,\n",
       "       -2.71642493e-04, -2.66301110e-02, -2.85013323e-03,  8.34047049e-02,\n",
       "        2.22190339e-02, -1.48995395e-03,  5.04696071e-02, -5.47958259e-03,\n",
       "        4.81736101e-02,  5.23570068e-02,  3.64142992e-02, -2.06352286e-02,\n",
       "       -2.47922763e-02,  8.09198171e-02, -3.31945438e-03,  3.30116227e-02,\n",
       "        1.13490608e-03,  5.39047469e-04,  6.46768464e-03,  3.97768319e-02,\n",
       "       -2.05054991e-02, -9.21727251e-03,  5.31698242e-02,  1.91433989e-02,\n",
       "        6.27155378e-02,  3.52466591e-02,  6.77745789e-02,  4.50557359e-02,\n",
       "        5.41484877e-02,  9.19863523e-04,  4.97967862e-02,  7.44256079e-02,\n",
       "        1.52706383e-02,  4.73760478e-02, -4.12092917e-02, -1.13364486e-02,\n",
       "        4.74533578e-03,  1.51853207e-02,  5.68654649e-02,  5.78778237e-02,\n",
       "       -2.65013818e-02,  2.01144461e-02,  3.19022574e-02, -6.28737453e-03,\n",
       "        5.54591864e-02, -6.92324620e-03,  5.22295982e-02,  4.02895212e-02,\n",
       "        1.63298827e-02,  4.43176851e-02, -4.26449105e-02,  1.79474975e-03,\n",
       "        1.93175320e-02,  4.66556102e-02,  1.12061938e-02, -3.32387388e-02,\n",
       "        7.00680986e-02,  7.63445795e-02,  2.08405089e-02, -2.20199879e-02,\n",
       "       -2.75350995e-02,  2.05132514e-02,  9.67233852e-02, -2.56020054e-02,\n",
       "       -3.38707753e-02,  8.07726011e-02,  3.96195874e-02,  3.24017294e-02,\n",
       "        5.75155914e-02,  1.00504704e-01,  5.96099906e-02,  8.69676322e-02,\n",
       "        7.34785050e-02, -1.33191235e-02,  5.55838868e-02, -9.92530026e-03,\n",
       "        3.88161317e-02,  8.11351612e-02,  8.23621303e-02,  1.77637581e-02,\n",
       "        6.80389851e-02,  4.89142053e-02,  3.20091732e-02, -1.82490498e-02,\n",
       "        6.51930273e-02, -3.04667782e-02,  3.10063120e-02,  4.68302332e-02,\n",
       "        3.80722951e-04,  2.63001937e-02,  4.06222828e-02, -2.14663669e-02,\n",
       "        5.38410321e-02, -1.77663788e-02, -3.00782137e-02,  7.30671808e-02,\n",
       "        1.36771454e-02,  2.41126362e-02,  1.56017914e-02,  7.05598286e-05,\n",
       "        3.61753032e-02,  5.70492931e-02,  3.02143041e-02,  7.53497854e-02,\n",
       "       -3.05911712e-02,  5.37349023e-02,  9.20389444e-02,  2.20018309e-02,\n",
       "        6.42280653e-02, -1.46163180e-02,  5.51993176e-02,  5.50438650e-02,\n",
       "        9.55587178e-02, -4.60150233e-03,  3.98220904e-02,  1.26065826e-02,\n",
       "       -2.69817282e-02,  1.42445872e-02,  7.99235702e-02,  3.74231897e-02,\n",
       "        5.82207069e-02, -1.19731072e-02,  4.90356497e-02,  7.42750661e-03,\n",
       "        9.19806063e-02,  4.74610273e-03, -1.77472420e-02, -8.76480713e-03,\n",
       "       -4.78484593e-02,  6.95626512e-02, -1.28177516e-02,  3.74395289e-02,\n",
       "       -4.66528395e-03,  9.77367610e-02,  6.18312061e-02, -2.68333796e-02,\n",
       "        4.08267826e-02, -1.22769065e-02,  1.35495933e-02, -3.17603685e-02,\n",
       "       -3.14636119e-02, -9.78012756e-03, -2.20393594e-02, -1.60158649e-02,\n",
       "        7.25466236e-02,  5.79203805e-03,  3.39882374e-02,  3.09330840e-02,\n",
       "        3.23193669e-02, -1.42570082e-02, -1.18087407e-03,  8.10162425e-02,\n",
       "        8.94426703e-02, -8.11518542e-03,  4.32912409e-02,  3.75255221e-03,\n",
       "        4.32459302e-02,  2.66390517e-02, -2.31011361e-02,  2.32192893e-02,\n",
       "        1.76665392e-02, -1.36745181e-02,  1.09003976e-01,  3.13866474e-02,\n",
       "        5.29234260e-02,  7.16359913e-02,  3.85712124e-02, -3.65698040e-02,\n",
       "        3.27571668e-02,  4.27272543e-02,  8.09175372e-02, -4.66284268e-02,\n",
       "        5.12042530e-02,  5.30143129e-03,  4.92790788e-02,  6.14578500e-02,\n",
       "       -8.98573641e-03,  1.91547964e-02,  2.92583797e-02, -3.40086818e-02,\n",
       "        6.49160817e-02,  3.19541655e-02,  8.43225271e-02, -6.27859216e-03,\n",
       "       -3.47472131e-02,  5.30235767e-02,  3.69576067e-02,  3.52199376e-02,\n",
       "       -4.28535491e-02, -4.71319184e-02,  4.74987132e-03,  2.86011118e-02,\n",
       "        6.63597807e-02,  7.98694864e-02,  1.25618996e-02,  6.92126006e-02,\n",
       "       -4.10098583e-02,  1.07873201e-01,  5.95475659e-02, -2.60185786e-02,\n",
       "        2.42041564e-03,  3.74863520e-02,  2.12039370e-02,  1.84801128e-02,\n",
       "        2.86500761e-03,  4.16166224e-02,  4.04902734e-03,  4.99483570e-02,\n",
       "       -2.51510460e-02,  5.22036180e-02,  8.23463723e-02,  2.56738011e-02,\n",
       "        1.24071632e-03, -4.35034893e-02,  9.02124420e-02,  1.67592941e-03,\n",
       "        2.32243328e-03,  4.06067409e-02,  2.14266870e-02,  6.21040165e-02,\n",
       "        3.44243757e-02,  7.87871517e-03,  4.59936745e-02,  5.00689261e-02,\n",
       "       -1.08473469e-02,  9.41011533e-02,  5.89410625e-02,  6.71205530e-03,\n",
       "        2.51318160e-02,  3.53845395e-02, -2.99314335e-02, -1.24917934e-02,\n",
       "        5.11749499e-02,  3.26325968e-02,  1.09045178e-01, -3.32748555e-02,\n",
       "        8.98126792e-03,  5.17325364e-02, -2.88220569e-02,  8.28033313e-03,\n",
       "        6.42675683e-02, -1.93166255e-03,  2.97130104e-02,  1.17357180e-01,\n",
       "        1.26799736e-02,  1.22824525e-02,  3.36603783e-02,  7.84072280e-02,\n",
       "        2.31934171e-02,  3.26201989e-04, -9.30630602e-03,  6.69027790e-02,\n",
       "        3.32972109e-02,  8.44955891e-02,  6.91272989e-02,  4.25284654e-02,\n",
       "        1.19575664e-01, -1.63458381e-03,  9.64318961e-03,  2.99359718e-03,\n",
       "       -3.01756114e-02, -1.14774145e-02,  6.38785912e-03,  5.97927235e-02,\n",
       "       -1.40865895e-05,  9.88064054e-03,  1.16435528e-01,  6.65384606e-02,\n",
       "        1.09481742e-03,  9.85501409e-02, -1.08906650e-03,  7.07571432e-02,\n",
       "        2.54350901e-02,  4.84251883e-03,  4.76527773e-02,  3.93582806e-02,\n",
       "        5.00382632e-02,  4.76797260e-02,  2.28713918e-02,  4.25205529e-02,\n",
       "       -8.08166899e-03,  5.19583784e-02,  1.09078325e-02,  2.50692889e-02,\n",
       "        5.60618080e-02,  2.14733789e-03,  5.39363399e-02,  1.00320637e-01,\n",
       "        1.05013326e-02,  9.35903937e-02,  4.08265777e-02,  4.71247807e-02,\n",
       "        9.87872947e-03,  5.23554944e-02,  4.71356586e-02,  2.05768254e-02,\n",
       "       -1.24565316e-02,  9.61295441e-02,  2.70191785e-02,  8.42357129e-02,\n",
       "       -3.72674316e-02,  6.02016151e-02,  1.22666610e-02,  4.75484133e-02,\n",
       "        8.84209797e-02,  4.06032093e-02,  2.04460453e-02,  5.05466238e-02,\n",
       "        9.54884887e-02,  7.14689940e-02, -1.74967796e-02, -5.91970840e-03,\n",
       "        5.98898754e-02, -2.30485536e-02,  1.98943857e-02,  5.00869900e-02,\n",
       "        7.74196582e-03,  2.63816565e-02, -9.51403228e-04, -3.60553060e-03,\n",
       "        5.45608886e-02,  5.46126366e-02,  5.03482483e-02,  6.20114338e-03,\n",
       "       -3.62370051e-02,  8.39213058e-02,  9.89878550e-02,  4.22776565e-02,\n",
       "       -3.85968038e-03, -1.36014037e-02,  1.30873928e-02,  8.66562277e-02,\n",
       "        4.26079594e-02,  4.77366298e-02,  3.11793704e-02,  2.52070334e-02,\n",
       "       -1.66994780e-02,  7.23973066e-02,  9.63140205e-02,  7.90805072e-02,\n",
       "        7.47015774e-02,  2.88935788e-02,  1.90035459e-02,  6.76681921e-02,\n",
       "        4.59540263e-02,  7.14137480e-02,  9.68627930e-02,  7.19205514e-02,\n",
       "        5.77208512e-02,  9.46543217e-02,  1.05371391e-02,  1.03404149e-01,\n",
       "       -5.36609488e-03,  1.02319553e-01, -3.69648598e-02,  1.26557443e-02,\n",
       "        3.03076878e-02, -2.55616754e-02,  6.11931607e-02,  1.65849403e-02,\n",
       "        2.91474350e-03, -9.72149428e-04,  1.34743331e-02, -3.51525769e-02,\n",
       "       -7.65618542e-03,  6.17066622e-02,  6.16344884e-02, -2.77079567e-02,\n",
       "        5.30886017e-02, -4.45413962e-03,  1.01985276e-01, -5.00002876e-02,\n",
       "        1.36452271e-02,  2.42589861e-02, -1.95898283e-02,  7.15207160e-02,\n",
       "        4.48001036e-03,  8.42295662e-02,  6.50991127e-03,  2.84746774e-02,\n",
       "        8.69557112e-02,  7.89971650e-03,  1.87394973e-02, -3.39476243e-02,\n",
       "       -1.73861347e-02,  9.13909748e-02,  1.09298438e-01,  3.20221260e-02,\n",
       "       -4.80718212e-03, -2.52010506e-02,  6.60750456e-03,  4.78469469e-02,\n",
       "        1.35142040e-02,  7.56530277e-03, -2.90832408e-02,  3.02013159e-02,\n",
       "       -2.24643089e-02,  1.10337421e-01,  3.94952856e-02, -3.43332998e-02,\n",
       "        4.28606048e-02,  2.34580580e-02, -7.66571320e-04,  2.63183061e-02,\n",
       "        1.77670494e-02,  9.36737061e-02,  9.18087289e-02, -1.58754367e-04,\n",
       "        3.33309323e-02,  1.01559632e-01,  8.91066864e-02,  3.57062370e-02,\n",
       "       -1.30841089e-03,  6.96388483e-02,  1.91324111e-02, -3.84715572e-02,\n",
       "        4.96890433e-02,  4.38112542e-02,  3.79313640e-02, -1.99307147e-02,\n",
       "       -2.69232541e-02,  1.42999450e-02,  5.79974763e-02,  7.77526647e-02,\n",
       "        5.96997961e-02,  4.32647802e-02,  1.52256954e-02,  3.57835181e-02,\n",
       "        6.39637560e-02,  8.03652704e-02,  8.46655816e-02, -1.89331826e-02,\n",
       "       -1.37684047e-02,  8.01879317e-02, -5.56592771e-04, -2.88388133e-02,\n",
       "        6.77315295e-02, -4.58998643e-02,  5.47870100e-02,  2.92260963e-02,\n",
       "        6.03935905e-02, -3.80740315e-02,  8.33968222e-02,  2.21540257e-02,\n",
       "        3.54516171e-02,  2.82142051e-02,  5.01518361e-02,  5.09879887e-02,\n",
       "        7.68416822e-02,  4.91106175e-02,  1.84030924e-03,  1.61882117e-02,\n",
       "        8.06417540e-02,  3.96770015e-02,  7.74907768e-02,  1.75399855e-02,\n",
       "        8.03011134e-02, -6.34636404e-03,  2.60609630e-02,  3.20323892e-02,\n",
       "        4.79036421e-02,  5.17656766e-02,  2.63660122e-02, -1.32859694e-02,\n",
       "        3.09063215e-02,  3.96842845e-02,  7.11464807e-02,  6.30489551e-03,\n",
       "        9.88196433e-02, -2.36534905e-02,  9.99089517e-03,  7.74973407e-02,\n",
       "        6.01044036e-02,  3.92851084e-02,  4.86238562e-02,  5.12831360e-02,\n",
       "        5.94950514e-03,  6.54489323e-02, -1.84835102e-02,  1.02090789e-02,\n",
       "        4.65325313e-03,  3.08974646e-02,  1.98135730e-02, -3.62773091e-02,\n",
       "       -6.90367864e-03, -1.61004886e-02,  8.62481147e-02,  1.94776021e-02,\n",
       "        7.50621734e-03,  9.96619985e-02,  6.80326968e-02, -2.02030363e-03,\n",
       "        6.79095089e-02,  6.83386996e-02, -1.45181203e-02,  6.71439245e-02,\n",
       "        8.77034217e-02, -3.10120694e-02,  5.27004451e-02,  1.15810730e-01,\n",
       "       -2.43330095e-02, -2.50058249e-02,  1.12076901e-01,  3.33727822e-02,\n",
       "        1.47564122e-02,  2.40002591e-02,  7.20285103e-02,  9.16832536e-02,\n",
       "        5.29056452e-02, -3.92878806e-04,  1.70272705e-03, -8.50494858e-03,\n",
       "       -2.24846099e-02,  1.06341280e-02,  4.31304872e-02, -2.87941820e-03,\n",
       "        6.84759170e-02,  7.24624991e-02,  2.47310027e-02,  5.75611880e-03,\n",
       "       -1.71452796e-03,  9.90029797e-03,  9.47157890e-02,  2.33803634e-02,\n",
       "       -3.89171913e-02, -1.00916279e-02,  1.18475910e-02,  3.98445912e-02,\n",
       "        7.63000473e-02, -2.34821532e-03,  2.19303425e-02,  5.93033545e-02,\n",
       "        1.38660064e-02,  9.50393453e-02,  3.51382941e-02,  4.89128344e-02,\n",
       "        5.15916012e-02,  3.40857022e-02,  7.50069022e-02,  3.99101935e-02,\n",
       "        4.45601977e-02, -4.26201150e-02,  9.22972038e-02,  4.84326929e-02,\n",
       "        7.81593472e-02, -4.37880214e-03,  2.48617884e-02,  7.99057409e-02,\n",
       "        7.69926086e-02,  8.35158825e-02,  7.78441951e-02, -1.59992818e-02,\n",
       "        3.04269437e-02,  9.90085229e-02, -2.49222443e-02,  4.57998514e-02,\n",
       "        1.63727105e-02,  1.60400942e-02,  1.78713053e-02,  3.78655754e-02,\n",
       "        4.60765176e-02,  1.14900249e-04, -2.14997809e-02,  2.51914328e-03,\n",
       "        4.43326980e-02,  5.69075719e-02,  1.41468812e-02,  2.70281248e-02,\n",
       "        7.68115446e-02, -6.28166832e-03,  1.00290954e-01,  1.08627625e-01,\n",
       "        3.77024934e-02,  3.24526615e-02, -1.79895572e-02,  6.77667409e-02,\n",
       "        4.48571555e-02,  5.46847004e-03, -3.48223411e-02,  2.40945071e-02,\n",
       "       -1.01827625e-02, -1.58538460e-03,  7.77308121e-02,  4.21237340e-03,\n",
       "        4.47190627e-02, -6.61157351e-03,  7.93984085e-02,  2.74846051e-02,\n",
       "        5.63649600e-03,  1.99207049e-02, -4.79258643e-03,  8.28221887e-02,\n",
       "        2.53509711e-02, -4.76587042e-02,  4.41678427e-02,  4.42130230e-02,\n",
       "        3.84177454e-02,  2.90963408e-02,  9.62581560e-02,  6.41834140e-02,\n",
       "        9.53172222e-02,  5.65638915e-02,  5.25244288e-02,  4.44842763e-02,\n",
       "        8.90919473e-03,  3.64907831e-02,  1.27624925e-02,  1.09113246e-01,\n",
       "        6.99561983e-02,  1.29226064e-02,  8.47552940e-02,  5.24221472e-02,\n",
       "        5.27377613e-02,  2.05553249e-02,  4.20286693e-02,  5.58410883e-02,\n",
       "       -1.23736737e-02,  7.17776269e-02,  1.39771402e-02,  8.88431072e-02,\n",
       "        2.20461655e-02,  6.82854205e-02,  3.77396047e-02,  3.48185822e-02,\n",
       "       -4.22699703e-03, -6.63512899e-03, -2.26621777e-02, -1.01062413e-02,\n",
       "        3.48774195e-02, -4.29542810e-02,  3.60447057e-02,  4.62900847e-02,\n",
       "        7.62084424e-02,  8.45640749e-02,  6.90666661e-02, -1.32913459e-02,\n",
       "        4.38572317e-02,  7.01035559e-02, -2.63153724e-02, -3.95610742e-02,\n",
       "        4.48456854e-02,  2.31511742e-02,  9.40435231e-02,  7.13474154e-02,\n",
       "        6.16304427e-02,  7.35571682e-02,  3.91425267e-02,  1.62782613e-02,\n",
       "        6.78812265e-02,  6.29257932e-02,  6.51987493e-02,  6.56998083e-02,\n",
       "        2.37214789e-02, -2.43970435e-02,  3.73603478e-02, -8.83045606e-03,\n",
       "        1.07346192e-01,  6.76152781e-02, -1.10477535e-02,  8.11203271e-02,\n",
       "        1.25623913e-02,  8.53858292e-02,  1.22223375e-02,  1.71389170e-02,\n",
       "       -1.00817010e-02, -2.50035971e-02, -2.93326620e-02,  6.06957190e-02,\n",
       "       -4.24501188e-02,  1.65415537e-02,  1.80255305e-02,  3.89619246e-02,\n",
       "       -2.69761197e-02, -3.53480643e-03, -1.86941996e-02,  4.38695215e-03,\n",
       "        1.05542596e-02,  7.46260360e-02, -3.43963727e-02,  6.20123632e-02,\n",
       "        8.33986774e-02, -8.40389915e-03, -2.55479058e-03, -5.09802531e-03,\n",
       "        3.99490148e-02,  9.50716585e-02,  7.06955567e-02,  5.79226762e-02,\n",
       "        5.54281473e-02,  3.51521112e-02, -3.33985798e-02,  6.42388761e-02,\n",
       "        6.68065250e-02,  5.05840294e-02,  3.45449820e-02,  1.00631475e-01,\n",
       "        4.49838750e-02,  2.97030322e-02,  3.48709449e-02,  8.54356289e-02,\n",
       "        5.29904366e-02,  5.16727343e-02,  5.07139927e-03,  4.26750816e-02,\n",
       "        6.61802068e-02, -1.23535516e-02, -1.54114077e-02,  6.31902888e-02,\n",
       "        1.03061255e-02,  2.55729239e-02,  7.79730454e-02,  1.80461258e-02,\n",
       "        2.09140256e-02, -2.14150380e-02,  6.10653386e-02,  2.23490689e-02,\n",
       "        1.75345782e-02,  2.37587970e-02,  3.03908088e-03,  6.53085811e-03,\n",
       "        4.96081151e-02,  6.97997957e-02, -3.56003493e-02,  4.90361974e-02,\n",
       "       -3.11960354e-02,  2.39692815e-02,  3.06118447e-02,  3.43958591e-03,\n",
       "        7.90766180e-02,  6.06970824e-02,  9.79327559e-02, -3.08102146e-02,\n",
       "        6.62492663e-02, -1.14984969e-02,  7.38674998e-02,  8.79840404e-02,\n",
       "       -4.30270069e-04,  1.66311339e-02, -2.93544978e-02, -3.12016252e-02,\n",
       "        4.52912487e-02, -6.34302991e-03,  4.42354241e-03,  6.50958493e-02,\n",
       "        4.39395793e-02,  3.66016943e-03,  2.71055624e-02,  6.05047420e-02,\n",
       "        1.06315240e-01,  7.49615207e-02,  3.07589751e-02,  7.98384175e-02,\n",
       "       -2.58405053e-04, -4.19545546e-03,  7.08835125e-02,  6.81885704e-02,\n",
       "        2.09813900e-02, -4.76579964e-02, -1.36737584e-03, -4.23274469e-03,\n",
       "        6.41376898e-02,  6.93965852e-02, -1.96571685e-02, -3.79865877e-02,\n",
       "        3.96483112e-03,  4.88282591e-02,  9.65967588e-03,  7.96512663e-02,\n",
       "        5.93111478e-02,  1.42150046e-02,  5.61091788e-02,  5.29728383e-02,\n",
       "        5.68266064e-02,  2.49894569e-03,  5.90742603e-02,  4.19629179e-02,\n",
       "        7.74580091e-02,  1.06976882e-01,  5.70414364e-02,  9.62322671e-03,\n",
       "       -4.48221253e-04,  3.43542472e-02, -3.93747836e-02,  3.98276336e-02,\n",
       "        7.66671146e-04, -2.38331780e-02,  8.14530775e-02,  1.31818941e-02,\n",
       "       -1.49772493e-02,  5.12221716e-02,  3.19122821e-02,  8.82152002e-04,\n",
       "        2.30232030e-02,  6.84587192e-03,  4.82190102e-02,  1.00051336e-01,\n",
       "       -1.34295439e-02, -3.91352586e-02,  9.48315263e-02,  6.87200800e-02,\n",
       "        6.37279451e-02,  5.44772809e-03,  1.03922494e-01,  2.52875071e-02,\n",
       "        8.52012560e-02,  2.55702846e-02,  6.11776225e-02, -1.08127566e-02,\n",
       "       -4.54762718e-03,  9.99248121e-04,  5.08671664e-02, -1.13032274e-02,\n",
       "        2.82446910e-02,  1.69886090e-02,  3.63469496e-02, -1.52205909e-02,\n",
       "        6.88688159e-02,  1.20514557e-02,  3.44468094e-02, -4.27965410e-02,\n",
       "       -2.66196504e-02,  5.61811700e-02,  8.92183185e-02, -2.39543077e-02,\n",
       "        1.11941263e-01,  2.05659512e-02,  4.81143557e-02,  3.01000737e-02,\n",
       "        2.02882979e-02,  4.18925798e-03,  4.81138602e-02,  3.90058905e-02,\n",
       "        2.29553948e-03,  8.97938237e-02, -1.72507353e-02, -5.99133363e-03,\n",
       "        1.17471464e-01,  2.78379936e-02,  8.18322040e-03,  9.04064178e-02,\n",
       "        1.21018169e-02,  8.00486356e-02,  3.97404730e-02,  9.94419213e-03,\n",
       "        5.53151369e-02, -2.40662098e-02,  8.19207132e-02, -1.70238968e-02,\n",
       "       -4.24805470e-03,  3.87737975e-02,  9.27910022e-03,  9.64891315e-02,\n",
       "        7.05786198e-02, -3.35612334e-02,  8.81139189e-02,  7.67123625e-02,\n",
       "        3.68380994e-02,  6.87150210e-02, -1.30985752e-02,  3.48955095e-02,\n",
       "        3.16889137e-02,  2.86047962e-02,  8.19338486e-02, -1.25946524e-02,\n",
       "        7.56654516e-03,  5.74888811e-02, -3.62101048e-02,  9.50305912e-05,\n",
       "       -3.49447392e-02,  6.88107237e-02, -2.52955779e-02,  4.31124009e-02,\n",
       "       -2.05568913e-02, -2.08576750e-02,  6.09682035e-03,  9.54713151e-02,\n",
       "        6.86322749e-02,  9.65946689e-02,  3.31396013e-02,  1.96264125e-02,\n",
       "        3.16107906e-02,  1.02471106e-01,  1.72820371e-02, -4.58046198e-02,\n",
       "        4.86501753e-02,  8.14486519e-02, -1.86973922e-02, -1.42811332e-03,\n",
       "        8.38676561e-03,  6.50087371e-02, -1.65472049e-02,  6.41021505e-02,\n",
       "        5.83023541e-02,  6.22083321e-02,  2.90049240e-02, -1.40465805e-02,\n",
       "        3.01461872e-02,  3.78046297e-02,  6.71214089e-02,  9.43509117e-02,\n",
       "        5.83802462e-02, -1.34577230e-02,  1.87743586e-02,  4.41037901e-02,\n",
       "        9.88979638e-03, -1.17791472e-02,  6.64692298e-02,  4.39427011e-02,\n",
       "        6.62042499e-02,  1.08356297e-01,  8.33723247e-02,  6.92700446e-02,\n",
       "        1.07722528e-01, -3.86054888e-02,  1.05746225e-01,  8.50067474e-03,\n",
       "       -1.88533477e-02,  9.16268691e-05, -2.30906345e-02,  8.19721818e-02,\n",
       "        5.11046611e-02,  4.52107750e-02,  1.24551626e-02,  7.40492865e-02,\n",
       "        7.15729296e-02,  1.69993509e-02,  1.86526347e-02,  9.59020332e-02,\n",
       "        5.47922887e-02, -7.26986630e-03,  9.71809328e-02,  8.55051428e-02,\n",
       "        8.88527557e-03,  4.19699103e-02,  8.24303702e-02, -2.16447003e-02,\n",
       "       -3.06080244e-02,  3.72843817e-02, -1.52174504e-02,  1.62573194e-03,\n",
       "        5.77193499e-02,  3.95990983e-02,  1.00786753e-01,  1.05532585e-02,\n",
       "        8.17415025e-03,  1.82225816e-02, -3.91389467e-02,  4.13154885e-02,\n",
       "        6.56368509e-02, -2.66764089e-02,  5.10461852e-02, -5.57439914e-03,\n",
       "        5.08610755e-02,  7.27553442e-02,  1.80579256e-02,  3.38619761e-02,\n",
       "        6.28168434e-02,  5.40979542e-02,  7.43959099e-02, -2.30183601e-02,\n",
       "        3.37472409e-02, -1.20263984e-02,  6.93816543e-02,  8.24249387e-02,\n",
       "       -2.04612855e-02, -4.25157174e-02,  1.70903113e-02, -4.40969579e-02,\n",
       "        6.89633116e-02,  9.15814862e-02,  2.73418408e-02,  2.88107228e-02,\n",
       "       -3.19903009e-02,  8.40723962e-02, -4.19256166e-02, -2.02656561e-03,\n",
       "       -5.47260046e-03,  1.80944130e-02,  1.27434462e-01, -1.13594234e-02,\n",
       "        6.01448491e-02, -4.03678976e-02,  1.43397413e-02, -2.38532368e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_pred=np.mean(pred,axis=0)\n",
    "mc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_obj(mc_pred, \"../pred_upd_hyb_MC_Xx.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
