{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "import random\n",
    "\n",
    "def pass_arg(nsim, tr_size):\n",
    "    print(\"Tr_size:\", tr_size)\n",
    "    def fix_seeds(seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    #     K.set_session(sess)\n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    ss = 1\n",
    "    fix_seeds(ss)\n",
    "\n",
    "\n",
    "    # import pickle\n",
    "\n",
    "    # def save_obj(obj, name):\n",
    "    #     with open(name, 'wb') as f:\n",
    "    #         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "    # # Making sure dimensionless bond length is less than 1\n",
    "    # def bond(bl):\n",
    "    #     return bl-1.0\n",
    "\n",
    "    # Making sure dimensionless bond length is less than 1\n",
    "    def bond(bl):\n",
    "        bln = -bl*(bl<0)\n",
    "        blp = bl*(bl>=1.0) - 1*(bl>=1.0)\n",
    "        return bln+blp\n",
    "\n",
    "    # # Making sure final porosity is less than initial\n",
    "    # def poros(poroi, porof):\n",
    "    # #     porof[porof < 0] = 1-porof[porof < 0]\n",
    "    #     porof[porof < 0] = poroi[0]-porof[porof < 0]\n",
    "    #     print(porof)\n",
    "    #     return porof-poroi\n",
    "\n",
    "    # Making sure final porosity is less than initial\n",
    "    def poros(poroi, porof):\n",
    "        porofn = -porof*(porof<0)\n",
    "        porofp = porof*(porof>=poroi) - poroi*(porof>=poroi)\n",
    "        return porofp+porofn\n",
    "\n",
    "    def strength1(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        corr_bl_sorted = np.sort(bl, axis=-1)  # sorts along first axis (down)\n",
    "        return corr_bl_sorted-bl_sorted\n",
    "\n",
    "    def strength2(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        return sum(bl_sorted[1:]-bl_sorted[:-1]<0)/14\n",
    "\n",
    "    def phy_loss_mean(params):\n",
    "        # useful for cross-checking training\n",
    "        loss1, loss2, loss3, loss4, lam1, lam2 = params\n",
    "        x1, x2, x3 = loss1*(loss1>0), loss2*(loss2>0), loss3*(loss3>0)\n",
    "\n",
    "        if x1.any() and x1.shape[0]>1:\n",
    "            X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "            x1 = X_scaled1\n",
    "        if x2.any() and x2.shape[0]>1:\n",
    "            X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "            x2 = X_scaled2\n",
    "        if x3.any() and x3.shape[0]>1:\n",
    "            X_scaled3 = (x3 - np.min(x3)) / (np.max(x3) - np.min(x3))\n",
    "            x3 = X_scaled3\n",
    "        return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3))\n",
    "    #     return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3) + lam2*loss4)\n",
    "\n",
    "    def PGNN_train_test(optimizer_name, optimizer_val, drop_rate, iteration, n_layers, n_nodes, tr_size, lamda, reg):\n",
    "\n",
    "        # Hyper-parameters of the training process\n",
    "    #     batch_size = int(tr_size/2)\n",
    "        batch_size = 1\n",
    "        num_epochs = 50\n",
    "        val_frac = 0.2\n",
    "        patience_val = 50\n",
    "\n",
    "        # Initializing results filename\n",
    "        exp_name = \"FeatureEng_\" + optimizer_name + '_drop' + str(drop_rate) + '_nL' + str(n_layers) + '_nN' + str(n_nodes) + '_trsize' + str(tr_size) + '_iter' + str(iteration)\n",
    "        exp_name = exp_name.replace('.','pt')\n",
    "        results_dir = '../results/'\n",
    "        model_name = results_dir + exp_name + '_NoPhyInfomodel.h5' # storing the trained model\n",
    "        if reg:\n",
    "            results_name = results_dir + exp_name + '_results_regularizer.dat' # storing the results of the model\n",
    "        else:\n",
    "            results_name = results_dir + exp_name + '_results.dat' # storing the results of the model\n",
    "\n",
    "        # Load labeled data\n",
    "        data = np.loadtxt('../data/labeled_data.dat')\n",
    "\n",
    "        # x_labeled = data[:, :-5] # -2 because we do not need porosity predictions\n",
    "        x_label = data[:, :-3] # -2 because we do not need porosity predictions\n",
    "        x_labeled = np.hstack((x_label[:,:2],x_label[:,-2:]))\n",
    "        y_labeled = data[:, -3:-1]\n",
    "\n",
    "        # normalize dataset with MinMaxScaler\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range=(0, 1.0))\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "        x_labeled = scaler.fit_transform(x_labeled)\n",
    "#         y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "        # train and test data\n",
    "        trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "    #     testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "    #     init_poro = data[tr_size:, -1]\n",
    "        testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "        init_poro = data[tr_size:, -1]\n",
    "\n",
    "        # Creating the model\n",
    "        model = Sequential()\n",
    "        for layer in np.arange(n_layers):\n",
    "            if layer == 0:\n",
    "                model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "            else:\n",
    "                if reg:\n",
    "                    model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=.001, l2=.001)))\n",
    "                else:\n",
    "                    model.add(Dense(n_nodes, activation='relu'))\n",
    "            model.add(Dropout(rate=drop_rate))\n",
    "        model.add(Dense(2, activation='linear'))\n",
    "\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizer_val,\n",
    "                      metrics=[root_mean_squared_error])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val,verbose=1)\n",
    "\n",
    "        print('Running...' + optimizer_name)\n",
    "        history = model.fit(trainX, trainY,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=num_epochs,\n",
    "                            verbose=0,\n",
    "                            validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "\n",
    "        test_score = model.evaluate(testX, testY, verbose=1)\n",
    "        print(test_score)\n",
    "        # predictions = model.predict(testX)\n",
    "    # #     inv_pred = scaler.inverse_transform(predictions)\n",
    "        # phyloss1 = bond(predictions[:,0]) # physics loss 1\n",
    "\n",
    "    # #     init_poro_ndim = np.ones((init_poro.shape))\n",
    "    # #     diff2 = poros(init_poro_ndim, predictions[:,1]) # physics loss 2\n",
    "\n",
    "        # phyloss2 = poros(init_poro, predictions[:,1]) # physics loss 2\n",
    "        # phyloss3 = strength1(predictions[:,0], predictions[:,1])\n",
    "        # phyloss4 = strength2(predictions[:,0], predictions[:,1])\n",
    "\n",
    "        # lam1, lam2 = lamda[0], lamda[1]    \n",
    "        # phyloss = phy_loss_mean([phyloss1, phyloss2, phyloss3, phyloss4, lam1, lam2])\n",
    "\n",
    "        # print('iter: ' + str(iteration) + \n",
    "              # ' nL: ' + str(n_layers) + ' nN: ' + str(n_nodes) + \n",
    "              # ' trsize: ' + str(tr_size) + \n",
    "              # ' TestRMSE: ' + str(test_score[1]) + ' PhyLoss: ' + str(phyloss), \"\\n\")\n",
    "\n",
    "    # #     model.save(model_name)\n",
    "\n",
    "        # # save results\n",
    "        # results = {'train_rmse':history.history['root_mean_squared_error'], \n",
    "                                    # 'val_rmse':history.history['val_root_mean_squared_error'],\n",
    "                                    # 'test_rmse':test_score[1], 'PhyLoss':phyloss}\n",
    "\n",
    "    #     save_obj(results, results_name)\n",
    "\n",
    "        # return results, results_name, predictions, testY, test_score[1]\n",
    "        # predictions = model.predict(Xx)\n",
    "\n",
    "        Xx = np.random.uniform(0,1,(1000,2))\n",
    "        xx1 = np.ones((1000,2))\n",
    "        Xx = np.hstack((Xx,xx1))\n",
    "        \n",
    "        samples = []\n",
    "        for i in range(int(nsim)):\n",
    "            print(\"simulation num:\",i)\n",
    "            predictions = model.predict(Xx)\n",
    "            predictions = predictions[:,1]\n",
    "            samples.append(predictions[:,np.newaxis])\n",
    "        return np.array(samples)\n",
    "\n",
    "\n",
    "\n",
    "    # Main Function\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        fix_seeds(1)\n",
    "\n",
    "        # List of optimizers to choose from    \n",
    "        optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "        optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "\n",
    "        # selecting the optimizer\n",
    "        optimizer_num = 1\n",
    "        optimizer_name = optimizer_names[optimizer_num]\n",
    "        optimizer_val = optimizer_vals[optimizer_num]\n",
    "\n",
    "        # Selecting Other Hyper-parameters\n",
    "        drop_rate = 0.1 # Fraction of nodes to be dropped out\n",
    "        n_layers = 2 # Number of hidden layers\n",
    "        n_nodes = 5 # Number of nodes per hidden layer\n",
    "\n",
    "        # # Iterating over different training fractions and splitting indices for train-test splits\n",
    "        # trsize_range = [4,6,8,10,20]\n",
    "\n",
    "        # #default training size = 5000\n",
    "        # tr_size = trsize_range[4]\n",
    "\n",
    "        tr_size = int(tr_size)\n",
    "\n",
    "        # use regularizer\n",
    "        reg = True\n",
    "\n",
    "        #set lamda=0 for pgnn0\n",
    "        lamda = [1, 1] # Physics-based regularization constant\n",
    "\n",
    "        # total number of runs\n",
    "        iter_range = np.arange(1)\n",
    "        testrmse=[]\n",
    "        # iterating through all possible params\n",
    "        for iteration in iter_range:\n",
    "            # results, result_file, pred, obs, rmse = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                            # iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "            # testrmse.append(rmse)\n",
    "            pred = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                            iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "    \n",
    "    return np.squeeze(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr_size: 20\n",
      "Running...Adadelta\n",
      "19/19 [==============================] - 0s 0us/step\n",
      "[0.012400937266647816, 0.08046581596136093]\n",
      "simulation num: 0\n"
     ]
    }
   ],
   "source": [
    "pred = pass_arg(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.45776011e-02,  2.30815168e-02,  2.03259010e-02,  1.39528751e-01,\n",
       "        1.84255809e-01, -6.21486604e-02,  2.27331340e-01,  2.56632626e-01,\n",
       "       -7.65216723e-03,  2.91096047e-03,  1.22273445e-01,  2.42310792e-01,\n",
       "        2.39707708e-01,  2.00557411e-01,  2.32819766e-01,  4.26305756e-02,\n",
       "        1.75245821e-01,  2.61462390e-01,  2.04539269e-01, -2.66691595e-02,\n",
       "        9.95132476e-02,  1.73993379e-01, -2.81058475e-02,  2.00330138e-01,\n",
       "        4.62243743e-02,  1.15881003e-02,  7.09427446e-02,  2.43616611e-01,\n",
       "        2.76532650e-01,  1.14828534e-02,  1.88667178e-01,  7.92982131e-02,\n",
       "        1.40024021e-01,  1.71897858e-01,  1.98799133e-01, -9.63576138e-03,\n",
       "        2.00292319e-01,  2.19365209e-01,  4.61429507e-02,  1.07035920e-01,\n",
       "        9.39395279e-04,  5.40488809e-02, -7.69187585e-02, -1.95134431e-03,\n",
       "        3.98395807e-02,  1.60604417e-01, -1.46006122e-02, -8.35527107e-03,\n",
       "        1.07134372e-01,  1.05417706e-02,  3.21459353e-01,  1.97135448e-01,\n",
       "        1.70085907e-01,  1.13698222e-01,  4.62481193e-02, -6.62417710e-03,\n",
       "        2.49257237e-01,  4.91856150e-02,  6.90886155e-02,  2.03570873e-01,\n",
       "       -5.41618988e-02,  2.14711457e-01, -1.06276609e-02,  3.48536149e-02,\n",
       "        8.80181938e-02, -7.67662004e-03,  3.20627302e-01,  1.39051318e-01,\n",
       "        8.57199728e-02,  1.12900920e-02,  1.44836456e-01,  2.96937734e-01,\n",
       "       -6.65390119e-03, -7.14444816e-02,  1.27478153e-01,  2.65351743e-01,\n",
       "        2.81181633e-01,  1.13068864e-01, -5.81671670e-02,  2.71947086e-01,\n",
       "        2.90124178e-01, -7.33807459e-02,  1.59691945e-02,  2.95987986e-02,\n",
       "       -2.43530422e-03, -3.01857144e-02, -2.15776041e-02, -5.70062399e-02,\n",
       "       -7.13279173e-02,  2.53094226e-01,  7.27132708e-03,  1.83341771e-01,\n",
       "        3.08865290e-02, -6.61440492e-02,  2.15162411e-02,  1.14143528e-01,\n",
       "       -3.63040417e-02,  2.85832211e-02,  6.97728395e-02,  1.99942052e-01,\n",
       "        2.58687884e-02,  2.94323653e-01,  7.79471397e-02,  3.31825912e-02,\n",
       "        1.64009362e-01,  4.60810661e-02,  6.24993816e-03,  2.61941463e-01,\n",
       "        7.10138679e-03,  2.30856270e-01,  2.66131192e-01, -3.34901437e-02,\n",
       "        9.03613567e-02,  4.59692851e-02,  1.25012964e-01,  1.63283259e-01,\n",
       "        7.93953389e-02,  1.48749799e-02,  7.48392045e-02,  4.49565686e-02,\n",
       "        2.65689135e-01,  3.61891910e-02, -8.67940411e-02,  6.86623156e-02,\n",
       "       -3.99186015e-02,  2.43702501e-01,  4.05185819e-02, -8.20224732e-03,\n",
       "       -8.11094567e-02,  2.07698345e-01,  1.58558041e-02,  1.05519988e-01,\n",
       "        2.87038743e-01,  1.12998530e-01, -2.74866223e-02,  2.94688586e-02,\n",
       "       -6.49594590e-02,  1.95268959e-01, -1.24994293e-02,  1.33462578e-01,\n",
       "       -1.97682157e-02,  1.74659431e-01,  2.39583671e-01,  2.21391529e-01,\n",
       "        3.22144330e-01,  2.77771764e-02,  1.82288170e-01,  3.77915725e-02,\n",
       "        1.71171069e-01, -8.20449963e-02,  2.00086609e-02,  2.59447515e-01,\n",
       "        4.46300805e-02,  1.88734740e-01,  1.09297976e-01,  2.96764612e-01,\n",
       "        2.90210396e-01,  2.00357497e-01,  2.61788279e-01,  2.54815817e-01,\n",
       "        1.09103248e-02,  1.59979939e-01,  1.82556659e-02,  8.01594853e-02,\n",
       "        8.54091346e-02,  1.99911416e-01,  1.63647652e-01, -2.09606662e-02,\n",
       "       -7.53553361e-02,  2.20021188e-01, -3.72315943e-03,  8.03797096e-02,\n",
       "        3.20499577e-02,  3.50438803e-02,  2.46140778e-01,  5.76765910e-02,\n",
       "        4.20038067e-02,  2.24440604e-01, -5.50988689e-02,  1.11476764e-01,\n",
       "       -4.24335003e-02, -6.33722246e-02, -2.32458115e-02,  3.08771759e-01,\n",
       "        3.64315249e-02,  3.16730104e-02, -6.16466850e-02,  3.29139173e-01,\n",
       "       -3.07419077e-02,  8.32832903e-02,  1.86921693e-02, -4.94760424e-02,\n",
       "        1.75663590e-01,  9.92567390e-02,  6.91378415e-02,  2.75748372e-01,\n",
       "       -8.16841349e-02,  4.40811366e-02, -4.46987972e-02,  1.86546117e-01,\n",
       "        2.89092183e-01,  4.64043133e-02,  4.61291224e-02,  5.03058881e-02,\n",
       "        3.29303592e-01,  3.30262303e-01,  2.08836854e-01,  9.30264369e-02,\n",
       "       -3.16284746e-02, -6.15142658e-02,  1.01268992e-01, -1.57420859e-02,\n",
       "        2.95589030e-01, -6.58207163e-02, -4.08179238e-02,  2.93899566e-01,\n",
       "        1.54983640e-01,  4.43844683e-02,  1.09750807e-01,  8.15014094e-02,\n",
       "        1.37342528e-01,  5.97414821e-02,  1.60634115e-01, -3.13529745e-02,\n",
       "        2.89145947e-01,  1.51976086e-02, -6.84796423e-02,  9.05819088e-02,\n",
       "        2.02136606e-01,  3.31339955e-01, -5.37462011e-02,  1.97874427e-01,\n",
       "        1.99646920e-01,  8.56420770e-03,  1.00296527e-01,  2.01842804e-02,\n",
       "        1.98342428e-02,  1.38922095e-01, -2.40214542e-03,  2.41716076e-02,\n",
       "        2.12722540e-01, -8.22909251e-02, -2.22275630e-02,  1.43560529e-01,\n",
       "        1.14655346e-01,  4.98121046e-02,  2.76794940e-01,  1.98297292e-01,\n",
       "        6.02718443e-04,  6.53520525e-02, -6.70071170e-02,  2.81291604e-01,\n",
       "        1.41912460e-01,  3.86711545e-02,  2.87860066e-01,  1.18323930e-01,\n",
       "       -1.32660121e-02,  1.80508643e-01,  7.64022395e-02, -7.98442587e-02,\n",
       "        8.21475983e-02,  1.16259642e-01,  4.28430997e-02, -3.86676788e-02,\n",
       "        5.75928949e-02,  1.61060989e-01,  2.18822956e-01,  7.29271770e-03,\n",
       "        4.60509993e-02, -5.39590418e-02, -7.98073411e-03,  3.52245644e-02,\n",
       "       -6.97255135e-02,  1.74428433e-01,  1.61671728e-01,  1.05661489e-01,\n",
       "        2.78496742e-01,  1.64774537e-01,  1.01101115e-01,  1.26874484e-02,\n",
       "        1.40667826e-01,  1.11780763e-01, -8.24008957e-02, -7.90583566e-02,\n",
       "        1.18418902e-01, -7.88039342e-02,  1.68843865e-01, -1.57881677e-02,\n",
       "        4.82971855e-02,  8.43732283e-02,  1.98912490e-02, -2.10084170e-02,\n",
       "       -2.62068287e-02,  1.84914209e-02,  1.24865085e-01,  2.91277599e-02,\n",
       "        1.79512471e-01, -3.08687240e-02,  1.28516257e-01,  6.72302246e-02,\n",
       "        3.22094150e-02,  1.53161421e-01, -3.25706825e-02, -4.78696674e-02,\n",
       "        7.42116868e-02, -6.61866963e-02,  2.68336963e-02,  1.02152079e-02,\n",
       "        1.55199423e-01,  2.86046434e-02,  2.00667083e-02,  7.77942240e-02,\n",
       "        2.23342121e-01, -3.67009565e-02,  4.61249538e-02,  1.13169365e-02,\n",
       "        3.07366163e-01, -1.80654377e-02,  1.64478213e-01, -4.86029014e-02,\n",
       "       -3.61374989e-02,  6.07042164e-02,  4.80140038e-02,  2.99229585e-02,\n",
       "       -4.72122580e-02, -1.20456629e-02,  2.44239062e-01,  2.16864765e-01,\n",
       "       -3.47433984e-03,  2.48374462e-01,  7.87403807e-02, -3.05322111e-02,\n",
       "        1.43173799e-01,  6.58593103e-02,  1.99774235e-01,  2.11149037e-01,\n",
       "       -3.61846536e-02, -2.31978893e-02,  2.11459380e-02,  1.36714429e-01,\n",
       "        3.00533235e-01, -3.04762647e-03, -6.50034249e-02,  1.34180672e-02,\n",
       "        2.00371712e-01,  1.75829351e-01,  1.33897811e-01, -1.20726824e-02,\n",
       "        1.15888380e-02,  3.24958041e-02,  6.79134652e-02,  9.10224393e-02,\n",
       "        2.62234986e-01, -1.29611716e-02, -6.73786476e-02, -1.52799860e-02,\n",
       "       -1.24449357e-02,  7.62887374e-02,  8.70711505e-02,  4.62134741e-02,\n",
       "        4.62150648e-02,  5.64147905e-03, -6.07028008e-02,  3.76799144e-02,\n",
       "       -2.20771208e-02, -6.63084686e-02,  1.20841414e-01, -7.13414848e-02,\n",
       "        1.74951851e-01, -6.44334629e-02,  2.75459588e-01,  1.08346060e-01,\n",
       "        4.27629538e-02,  2.68528193e-01, -3.53994146e-02,  9.81548578e-02,\n",
       "        1.81754082e-01,  1.68789148e-01,  1.67683184e-01,  2.59837717e-01,\n",
       "        1.61415339e-01, -3.22760269e-03,  4.05328944e-02,  2.62594402e-01,\n",
       "        2.61609387e-02,  1.81540370e-01, -8.65287706e-02,  3.24984848e-01,\n",
       "        1.05106220e-01,  9.56926346e-02,  2.42246717e-01, -4.02872190e-02,\n",
       "        1.49399683e-01, -6.07544929e-02,  1.58753231e-01,  6.56702965e-02,\n",
       "       -4.42403406e-02,  1.82524502e-01,  8.14312845e-02,  3.09040070e-01,\n",
       "        2.39596009e-01,  1.72468238e-02, -7.19357058e-02,  4.59946208e-02,\n",
       "        1.50241956e-01,  2.60509193e-01,  1.19611248e-01, -2.68467888e-03,\n",
       "        1.17065795e-01,  1.53575242e-01,  2.60800421e-01,  2.79170778e-02,\n",
       "        2.31375009e-01, -8.10836777e-02,  4.33716513e-02,  2.86599040e-01,\n",
       "        1.26203708e-02,  4.59161848e-02,  1.64401174e-01,  5.60417958e-02,\n",
       "        1.03986248e-01, -4.53837514e-02, -4.20121998e-02,  1.39949813e-01,\n",
       "        6.82162121e-02, -5.41884527e-02,  9.72160697e-03,  5.34503758e-02,\n",
       "        1.57850444e-01, -3.49360704e-02,  6.45656884e-02,  3.07281941e-01,\n",
       "       -1.52652636e-02, -4.64957133e-02, -1.59808174e-02,  2.47897267e-01,\n",
       "        2.39957392e-01,  1.48117244e-01,  4.32043858e-02, -1.99455097e-02,\n",
       "       -2.74712592e-03,  4.41409312e-02,  1.49369702e-01,  6.85470030e-02,\n",
       "       -2.87572071e-02, -5.02255931e-02,  1.81328952e-02,  2.55976558e-01,\n",
       "        2.16037154e-01,  2.97683850e-03,  1.76363140e-01,  2.78580725e-01,\n",
       "       -2.91067362e-02,  3.11557591e-01, -4.22974452e-02,  7.40275532e-02,\n",
       "        3.34591568e-02,  2.79366612e-01, -6.74884394e-02,  1.08823106e-01,\n",
       "        5.84504083e-02,  2.24675443e-02,  2.48714723e-02, -2.13688612e-02,\n",
       "       -2.92655826e-02,  2.67602243e-02,  1.78207606e-01,  1.19522132e-01,\n",
       "       -7.65012279e-02,  2.83116139e-02,  1.65439658e-02,  1.08391479e-01,\n",
       "        3.86436060e-02,  2.07992047e-01,  7.30493218e-02,  6.88150674e-02,\n",
       "       -5.47620654e-03,  4.62576859e-02,  7.99810663e-02,  2.40224510e-01,\n",
       "        7.65643045e-02,  2.44128741e-02, -4.33685854e-02,  1.33517593e-01,\n",
       "       -2.30389684e-02,  2.45203406e-01,  1.88338399e-01, -2.85455957e-02,\n",
       "       -2.41570175e-03,  6.28260300e-02,  2.93202531e-02,  4.11884822e-02,\n",
       "        1.83256060e-01,  3.55901793e-02,  2.41943181e-01,  1.38925254e-01,\n",
       "        1.60170123e-01,  6.53371960e-02,  7.30580613e-02,  3.07762414e-01,\n",
       "        1.71317697e-01,  2.27343440e-01, -3.90648842e-02,  1.08761869e-01,\n",
       "        1.03076883e-01, -6.69371486e-02, -1.98260993e-02,  1.78423584e-01,\n",
       "       -2.36539692e-02, -7.34146982e-02,  2.33203679e-01,  4.17394340e-02,\n",
       "       -7.62927160e-02,  2.75030941e-01,  4.63703498e-02, -8.70838091e-02,\n",
       "        2.60358781e-01,  2.47031361e-01, -3.21645364e-02,  4.36036736e-02,\n",
       "        5.95123991e-02,  9.91260856e-02, -7.77761266e-02, -1.91113278e-02,\n",
       "        4.51425314e-02,  1.21092267e-01,  1.63914204e-01,  1.50977001e-01,\n",
       "        2.84500808e-01,  1.25161082e-01,  1.01746991e-02,  2.17844486e-01,\n",
       "       -7.35713318e-02, -5.26439771e-03,  1.04094736e-01,  1.20353572e-01,\n",
       "        1.94810063e-01,  1.31701246e-01, -6.69958219e-02,  8.22712034e-02,\n",
       "        3.01675975e-01,  2.24278152e-01,  1.34840727e-01,  7.69205913e-02,\n",
       "       -2.64391303e-03,  1.72046557e-01,  8.04375634e-02,  5.54211438e-05,\n",
       "        8.56367275e-02, -7.27946684e-02,  3.63489985e-02,  1.83655154e-02,\n",
       "        1.76736005e-02,  4.34713215e-02,  2.09426060e-02,  3.67843397e-02,\n",
       "        9.24926996e-03,  3.24672610e-01, -5.20026386e-02, -2.45326534e-02,\n",
       "       -4.27636430e-02,  2.12735295e-01,  8.80207568e-02, -4.85346317e-02,\n",
       "       -2.07685456e-02, -9.20770317e-03, -4.30250764e-02,  2.17624694e-01,\n",
       "        5.48339374e-02, -7.04227239e-02,  2.69988000e-01, -2.85691023e-02,\n",
       "        1.00769967e-01,  1.10865325e-01,  1.12897955e-01,  2.85174958e-02,\n",
       "        8.81833583e-03,  1.70340598e-01,  2.83567995e-01,  1.57511055e-01,\n",
       "        4.60744128e-02, -4.51716185e-02,  1.34398371e-01,  5.43618612e-02,\n",
       "       -3.77221107e-02,  1.64824113e-01, -5.64658791e-02, -8.77634212e-02,\n",
       "        5.54631613e-02,  6.51314780e-02,  2.13080138e-01, -2.86401287e-02,\n",
       "        2.30323039e-02,  1.66752577e-01,  3.07626575e-01,  3.79794836e-02,\n",
       "        2.44905531e-01,  1.78037614e-01,  2.46268101e-02,  1.54639095e-01,\n",
       "        5.12026623e-03,  2.19993412e-01, -4.28775996e-02,  3.46845798e-02,\n",
       "        2.08445549e-01,  1.17089421e-01,  1.85086340e-01, -6.10625148e-02,\n",
       "        5.23054153e-02,  3.27120781e-01,  6.34837002e-02,  9.27424803e-03,\n",
       "        3.80236432e-02,  4.26733904e-02, -6.71948269e-02, -2.81007960e-02,\n",
       "       -5.15252426e-02,  2.27559023e-02,  6.21477887e-03,  1.86595060e-02,\n",
       "        1.26760766e-01,  6.99585378e-02,  1.40939042e-01, -4.96864393e-02,\n",
       "       -1.61888525e-02,  1.13004588e-01,  4.58223373e-03, -2.35190690e-02,\n",
       "       -4.89810109e-03,  1.00364164e-01,  2.62489989e-02, -9.16914642e-03,\n",
       "        1.97136134e-01,  2.65761837e-03,  9.95128304e-02, -2.37921402e-02,\n",
       "        7.09893554e-02,  1.53281875e-02,  4.53679115e-02,  5.30177690e-02,\n",
       "        1.49724752e-01,  2.02725619e-01,  2.55282760e-01,  2.01353461e-01,\n",
       "        6.81350976e-02,  3.25667500e-01,  9.57704708e-03,  3.62150893e-02,\n",
       "        4.43975590e-02, -5.19913733e-02, -4.98753563e-02,  2.19216347e-01,\n",
       "        3.78243253e-02, -2.56906524e-02,  2.79450476e-01,  3.12215179e-01,\n",
       "        4.40065265e-02,  4.60398495e-02, -8.26933905e-02,  4.62874025e-02,\n",
       "       -3.85278612e-02,  1.08781531e-02,  3.49550657e-02,  1.07342929e-01,\n",
       "        4.03572246e-03,  1.51873939e-02, -2.86013186e-02,  1.84481032e-02,\n",
       "        7.07571357e-02,  2.34905511e-01,  4.18898053e-02,  2.09482610e-01,\n",
       "       -6.99228793e-02, -4.09922823e-02,  1.90682799e-01, -4.21063155e-02,\n",
       "        8.50827619e-02, -2.44099200e-02,  1.63454890e-01,  9.19235125e-02,\n",
       "        2.03083724e-01,  2.55185694e-01,  2.87551075e-01, -2.41596475e-02,\n",
       "        3.22194993e-01,  1.14961654e-01,  1.21204928e-01,  4.37776148e-02,\n",
       "        2.53541082e-01,  1.42268032e-01,  2.61193395e-01,  1.58347279e-01,\n",
       "        1.18839972e-01, -3.12497094e-03,  2.94909924e-01,  2.88757868e-02,\n",
       "       -2.21519843e-02,  2.33453304e-01,  1.78843826e-01,  1.52294189e-01,\n",
       "        1.66247375e-02, -8.63290802e-02, -6.63351789e-02, -1.22491196e-02,\n",
       "       -4.34816331e-02,  8.95549655e-02,  2.89985597e-01,  5.01475483e-03,\n",
       "       -4.68219370e-02,  1.83757767e-02,  4.93066460e-02, -8.85078385e-02,\n",
       "       -1.62554458e-02,  3.89424190e-02,  2.44056787e-02, -2.54271552e-02,\n",
       "       -1.19358823e-02, -1.20779611e-02,  1.56633347e-01,  1.19681694e-02,\n",
       "        4.63873781e-02,  2.20381856e-01,  2.12847382e-01,  3.67908999e-02,\n",
       "        1.44143969e-01,  5.60297295e-02, -3.71809006e-02,  1.05875961e-01,\n",
       "        9.89262313e-02,  2.15355366e-01, -1.63856596e-02,  4.66898419e-02,\n",
       "        1.26436159e-01,  4.81341556e-02,  1.69442385e-01,  1.47716120e-01,\n",
       "        1.29418708e-02, -1.90766901e-03,  3.08691919e-01, -2.72144526e-02,\n",
       "        3.02462101e-01,  8.17215219e-02,  4.61027063e-02,  1.27521098e-01,\n",
       "       -3.51920053e-02, -4.50276807e-02, -7.99610987e-02,  2.74129957e-01,\n",
       "       -1.93917826e-02,  2.12518990e-01, -3.29613090e-02, -6.72250614e-02,\n",
       "        2.06666172e-01,  6.16585054e-02,  2.88248837e-01,  2.84488380e-01,\n",
       "        2.35386081e-02,  2.24069595e-01,  1.71759099e-01, -7.53892958e-03,\n",
       "        2.77891010e-03,  1.56889617e-01,  3.36354077e-02,  4.62223925e-02,\n",
       "       -6.83100447e-02,  3.71030904e-02,  1.01845376e-02,  3.30527052e-02,\n",
       "        1.91322237e-01,  1.48174658e-01,  1.98089015e-02, -1.37952492e-02,\n",
       "        1.19380511e-01,  3.30604255e-01,  1.54312775e-01,  2.00679928e-01,\n",
       "       -9.41411778e-03,  6.46580011e-03,  2.49935389e-01,  3.01863074e-01,\n",
       "        9.91678834e-02,  3.31043340e-02,  1.15851633e-01, -4.03252244e-02,\n",
       "       -4.05554548e-02,  1.36256665e-01,  4.56005149e-02, -1.77441910e-02,\n",
       "       -4.94463667e-02,  1.66737452e-01, -9.22472030e-03,  4.14717048e-02,\n",
       "        9.24648345e-03, -7.76548758e-02,  2.70370189e-02,  1.41376853e-01,\n",
       "        1.82240963e-01,  3.46835107e-02,  3.06898773e-01,  3.82146761e-02,\n",
       "        1.42591894e-01,  2.84320533e-01, -3.51037681e-02,  1.23561658e-01,\n",
       "        2.71085590e-01, -2.24904865e-02,  4.60394099e-02,  1.70938641e-01,\n",
       "        1.19235352e-01,  1.44366771e-01, -1.32312588e-02, -4.33155671e-02,\n",
       "        2.44962990e-01,  3.17582518e-01, -5.93405887e-02, -2.08556205e-02,\n",
       "        3.22372466e-02,  1.59906313e-01, -7.86642656e-02,  6.31840527e-02,\n",
       "       -8.80082771e-02,  8.40465650e-02,  4.37331907e-02,  2.07391053e-01,\n",
       "        1.93339556e-01,  1.63279876e-01,  2.59784963e-02,  2.07606971e-01,\n",
       "        8.22329000e-02,  1.18164524e-01,  4.26322669e-02,  2.34387428e-01,\n",
       "        3.33353281e-02,  1.34499624e-01,  4.04143333e-02,  3.21421683e-01,\n",
       "        2.69317597e-01,  2.58904863e-02, -4.70603257e-02,  2.76757240e-01,\n",
       "       -2.58410424e-02,  7.32082352e-02,  1.06128678e-02,  1.04079887e-01,\n",
       "        1.32590294e-01,  1.15547076e-01,  3.03518735e-02,  2.03802083e-02,\n",
       "        1.91761464e-01, -4.82927784e-02,  2.36352533e-01,  1.58293486e-01,\n",
       "       -8.35509226e-02,  4.61402275e-02,  1.17671385e-01, -2.01341733e-02,\n",
       "        1.22260049e-01, -3.14481854e-02,  4.59841006e-02,  1.74927980e-01,\n",
       "        3.81599627e-02,  2.64578819e-01,  9.48263705e-03,  2.08775967e-01,\n",
       "        1.97486430e-01,  2.45708451e-02,  1.48802757e-01, -3.80058587e-03,\n",
       "       -1.55766457e-02,  2.75799662e-01, -6.04548901e-02, -5.88420406e-03,\n",
       "        6.20284602e-02,  4.61555906e-02,  2.15735823e-01,  1.57021247e-02,\n",
       "        9.58015844e-02,  1.05866760e-01,  6.12618774e-03,  1.96378350e-01,\n",
       "        1.43530741e-01,  1.95906162e-02,  2.98902720e-01,  1.75651312e-01,\n",
       "        2.93055654e-01, -1.13881640e-02,  2.80351371e-01,  4.60357964e-02,\n",
       "        2.66611338e-01,  2.44057685e-01,  1.41578987e-01, -6.21280074e-02,\n",
       "       -2.66212597e-02, -7.30502829e-02,  4.15933914e-02,  7.52731189e-02,\n",
       "        7.38944635e-02, -6.79704323e-02,  1.00279212e-01,  3.18864852e-01,\n",
       "        3.38335894e-02,  4.63122539e-02,  2.41483390e-01,  1.22195415e-01,\n",
       "        1.42065942e-01, -2.73732916e-02,  2.54208267e-01, -2.38064602e-02,\n",
       "       -7.12765083e-02,  4.63532507e-02,  9.99720469e-02,  2.16345787e-01,\n",
       "        4.88542430e-02,  1.09307989e-02, -2.15622261e-02,  3.56456637e-03,\n",
       "        2.26901062e-02,  2.10772693e-01,  1.55112445e-01,  3.66858691e-02,\n",
       "        1.10516757e-01,  2.07772255e-01,  9.05170664e-03,  3.42408344e-02,\n",
       "       -3.06788459e-02, -8.23420063e-02,  3.62444334e-02, -5.37320152e-02,\n",
       "       -4.28742394e-02,  2.99196839e-01, -3.46676856e-02,  1.59109861e-01,\n",
       "        2.77525663e-01,  2.01050878e-01,  2.40394354e-01, -3.00625190e-02,\n",
       "        3.42237316e-02,  9.54557955e-03,  1.73128992e-01, -6.18117452e-02,\n",
       "        4.71172482e-03,  1.30894497e-01,  6.01433367e-02, -6.61102161e-02,\n",
       "       -2.54394785e-02,  2.14427680e-01, -7.43121430e-02, -4.96723652e-02,\n",
       "        1.13369554e-01,  2.98939086e-02, -7.62612522e-02,  2.33580440e-01,\n",
       "        2.98511624e-01,  4.54085022e-02,  2.21921176e-01,  1.54555887e-01,\n",
       "       -2.31063738e-02,  1.67785026e-02, -6.00497499e-02,  1.17635153e-01,\n",
       "        1.51410729e-01,  1.06718846e-01,  2.93125004e-01,  4.01585475e-02,\n",
       "       -4.57707942e-02,  2.51051098e-01, -4.14255932e-02,  1.99347675e-01,\n",
       "        4.63467836e-02, -8.18079337e-03,  4.60778661e-02,  8.54228437e-02,\n",
       "       -1.19577423e-02,  4.34944965e-02, -8.37075710e-03,  2.73073882e-01,\n",
       "        3.60415466e-02,  2.14701891e-01,  4.29189205e-02,  1.85036715e-02,\n",
       "        2.76595235e-01,  3.16828281e-01,  9.05293673e-02,  3.23257893e-01,\n",
       "        4.62839045e-02, -5.58269545e-02,  8.30771327e-02,  1.02647215e-01,\n",
       "        2.89537549e-01,  1.43470839e-02,  3.20847452e-01,  1.76287442e-01,\n",
       "        1.71889275e-01,  7.82879144e-02, -6.53640330e-02,  2.32394576e-01,\n",
       "       -2.19138116e-02,  3.12436312e-01,  5.77386394e-02,  2.68186122e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_obj(pred, \"../pred_hyb_Xx.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
