{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "import random\n",
    "\n",
    "def fix_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "#     K.set_session(sess)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    \n",
    "ss = 1\n",
    "fix_seeds(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "import random\n",
    "\n",
    "def pass_arg(Xx, nsim, nobs):\n",
    "\n",
    "    def fix_seeds(seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    #     K.set_session(sess)\n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    ss = 1\n",
    "    fix_seeds(ss)\n",
    "\n",
    "\n",
    "    # import pickle\n",
    "\n",
    "    # def save_obj(obj, name):\n",
    "    #     with open(name, 'wb') as f:\n",
    "    #         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "    # # Making sure dimensionless bond length is less than 1\n",
    "    # def bond(bl):\n",
    "    #     return bl-1.0\n",
    "\n",
    "    # Making sure dimensionless bond length is less than 1\n",
    "    def bond(bl):\n",
    "        bln = -bl*(bl<0)\n",
    "        blp = bl*(bl>=1.0) - 1*(bl>=1.0)\n",
    "        return bln+blp\n",
    "\n",
    "    # # Making sure final porosity is less than initial\n",
    "    # def poros(poroi, porof):\n",
    "    # #     porof[porof < 0] = 1-porof[porof < 0]\n",
    "    #     porof[porof < 0] = poroi[0]-porof[porof < 0]\n",
    "    #     print(porof)\n",
    "    #     return porof-poroi\n",
    "\n",
    "    # Making sure final porosity is less than initial\n",
    "    def poros(poroi, porof):\n",
    "        porofn = -porof*(porof<0)\n",
    "        porofp = porof*(porof>=poroi) - poroi*(porof>=poroi)\n",
    "        return porofp+porofn\n",
    "\n",
    "    # def strength(bl, porof, nlayer=6):\n",
    "    #     discp = []\n",
    "    #     sigma01, sigma02 = 6, 31\n",
    "    #     C1s = 21\n",
    "    #     sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "    # #     print(\"sigma_long:\",sigma_long)\n",
    "    #     for i in range(len(sigma_long)):\n",
    "    #         for j in range(i + 1, len(sigma_long)):\n",
    "    #             if (sigma_long[j] > sigma_long[i]):\n",
    "    #                 discp.append(bl[i] - bl[j])\n",
    "    #     discp = np.array(discp)\n",
    "    #     print(discp)\n",
    "    #     return discp\n",
    "\n",
    "    def strength1(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        corr_bl_sorted = np.sort(bl, axis=-1)  # sorts along first axis (down)\n",
    "        return corr_bl_sorted-bl_sorted\n",
    "\n",
    "    def strength2(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        return sum(bl_sorted[1:]-bl_sorted[:-1]<0)/14\n",
    "\n",
    "    def phy_loss_mean(params):\n",
    "        # useful for cross-checking training\n",
    "        loss1, loss2, loss3, loss4, lam1, lam2 = params\n",
    "        x1, x2, x3 = loss1*(loss1>0), loss2*(loss2>0), loss3*(loss3>0)\n",
    "    #     print(np.mean(x1), x1.shape[0])\n",
    "    #     print(np.mean(x2), x2.shape[0])\n",
    "    #     print(np.mean(x3), x3.shape[0])\n",
    "\n",
    "        if x1.any() and x1.shape[0]>1:\n",
    "            X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "            x1 = X_scaled1\n",
    "        if x2.any() and x2.shape[0]>1:\n",
    "            X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "            x2 = X_scaled2\n",
    "        if x3.any() and x3.shape[0]>1:\n",
    "            X_scaled3 = (x3 - np.min(x3)) / (np.max(x3) - np.min(x3))\n",
    "            x3 = X_scaled3\n",
    "        return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3))\n",
    "    #     return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3) + lam2*loss4)\n",
    "\n",
    "    # def phy_loss_mean(params):\n",
    "    #     # useful for cross-checking training\n",
    "    #     diff1, diff2, lam1, lam2 = params\n",
    "    #     x1, x2 = diff1*(diff1>0), diff2*(diff2>0)\n",
    "    #     if np.any(x1):\n",
    "    #         X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "    #         x1 = X_scaled1\n",
    "    #     if np.any(x2):\n",
    "    #         X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "    #         x2 = X_scaled2\n",
    "    #     return lam1*np.mean(x1) + lam2*np.mean(x2)\n",
    "\n",
    "    def PGNN_train_test(optimizer_name, optimizer_val, drop_rate, iteration, n_layers, n_nodes, tr_size, lamda, reg):\n",
    "\n",
    "        # Hyper-parameters of the training process\n",
    "    #     batch_size = int(tr_size/2)\n",
    "        batch_size = 2\n",
    "        num_epochs = 200\n",
    "        val_frac = 0.2\n",
    "        patience_val = 50\n",
    "\n",
    "        # Initializing results filename\n",
    "        exp_name = optimizer_name + '_drop' + str(drop_rate) + '_nL' + str(n_layers) + '_nN' + str(n_nodes) + '_trsize' + str(tr_size) + '_iter' + str(iteration)\n",
    "        exp_name = exp_name.replace('.','pt')\n",
    "        results_dir = '../results/'\n",
    "        model_name = results_dir + exp_name + '_NoPhyInfomodel.h5' # storing the trained model\n",
    "        if reg:\n",
    "            results_name = results_dir + exp_name + '_results_regularizer.dat' # storing the results of the model\n",
    "        else:\n",
    "            results_name = results_dir + exp_name + '_results.dat' # storing the results of the model\n",
    "\n",
    "        # Load labeled data\n",
    "        data = np.loadtxt('../data/labeled_data.dat')\n",
    "    #     data = np.loadtxt('../data/labeled_data_BK_constw_unique.dat')\n",
    "    #     data = np.loadtxt('../data/labeled_data_BK_constw_v2.dat')\n",
    "        x_labeled = data[:, :-5] # -2 because we do not need porosity predictions\n",
    "        y_labeled = data[:, -3:-1]\n",
    "\n",
    "        # normalize dataset with MinMaxScaler\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range=(0, 1.0))\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "        x_labeled = scaler.fit_transform(x_labeled)\n",
    "    #     y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "        # train and test data\n",
    "        trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "    #     testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "    #     init_poro = data[tr_size:, -1]\n",
    "        testX, testY = x_labeled[20:,:], y_labeled[20:]\n",
    "        init_poro = data[20:, -1]\n",
    "\n",
    "        # Creating the model\n",
    "        model = Sequential()\n",
    "        for layer in np.arange(n_layers):\n",
    "            if layer == 0:\n",
    "                model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "            else:\n",
    "                if reg:\n",
    "                    model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=.001, l2=.001)))\n",
    "                else:\n",
    "                    model.add(Dense(n_nodes, activation='relu'))\n",
    "            model.add(Dropout(rate=drop_rate))\n",
    "        model.add(Dense(2, activation='linear'))\n",
    "\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizer_val,\n",
    "                      metrics=[root_mean_squared_error])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val,verbose=1)\n",
    "\n",
    "        print('Running...' + optimizer_name)\n",
    "        history = model.fit(trainX, trainY,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=num_epochs,\n",
    "                            verbose=0,\n",
    "                            validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "\n",
    "        test_score = model.evaluate(testX, testY, verbose=1)\n",
    "\n",
    "        predictions = model.predict(testX)\n",
    "    #     inv_pred = scaler.inverse_transform(predictions)\n",
    "        phyloss1 = bond(predictions[:,0]) # physics loss 1\n",
    "\n",
    "    #     init_poro_ndim = np.ones((init_poro.shape))\n",
    "    #     diff2 = poros(init_poro_ndim, predictions[:,1]) # physics loss 2\n",
    "\n",
    "        phyloss2 = poros(init_poro, predictions[:,1]) # physics loss 2\n",
    "        phyloss3 = strength1(predictions[:,0], predictions[:,1])\n",
    "        phyloss4 = strength2(predictions[:,0], predictions[:,1])\n",
    "\n",
    "        lam1, lam2 = lamda[0], lamda[1]    \n",
    "        phyloss = phy_loss_mean([phyloss1, phyloss2, phyloss3, phyloss4, lam1, lam2])\n",
    "\n",
    "        print('iter: ' + str(iteration) + \n",
    "              ' nL: ' + str(n_layers) + ' nN: ' + str(n_nodes) + \n",
    "              ' trsize: ' + str(tr_size) + \n",
    "              ' TestRMSE: ' + str(test_score[1]) + ' PhyLoss: ' + str(phyloss), \"\\n\")\n",
    "\n",
    "    #     model.save(model_name)\n",
    "\n",
    "        # save results\n",
    "        results = {'train_rmse':history.history['root_mean_squared_error'], \n",
    "                                    'val_rmse':history.history['val_root_mean_squared_error'],\n",
    "                                    'test_rmse':test_score[1], 'PhyLoss':phyloss}\n",
    "\n",
    "    #     save_obj(results, results_name)\n",
    "\n",
    "        return results, results_name, predictions, testY, test_score[1]\n",
    "\n",
    "\n",
    "\n",
    "    # Main Function\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        fix_seeds(1)\n",
    "\n",
    "        # List of optimizers to choose from    \n",
    "        optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "        optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "\n",
    "        # selecting the optimizer\n",
    "        optimizer_num = 1\n",
    "        optimizer_name = optimizer_names[optimizer_num]\n",
    "        optimizer_val = optimizer_vals[optimizer_num]\n",
    "\n",
    "        # Selecting Other Hyper-parameters\n",
    "        drop_rate = 0 # Fraction of nodes to be dropped out\n",
    "        n_layers = 2 # Number of hidden layers\n",
    "        n_nodes = 10 # Number of nodes per hidden layer\n",
    "\n",
    "        # Iterating over different training fractions and splitting indices for train-test splits\n",
    "        trsize_range = [4,6,8,10,20]\n",
    "\n",
    "        #default training size = 5000\n",
    "        tr_size = trsize_range[4]\n",
    "\n",
    "        # use regularizer\n",
    "        reg = True\n",
    "\n",
    "        #set lamda=0 for pgnn0\n",
    "        lamda = [1, 1] # Physics-based regularization constant\n",
    "\n",
    "        # total number of runs\n",
    "        iter_range = np.arange(1)\n",
    "        testrmse=[]\n",
    "        # iterating through all possible params\n",
    "        for iteration in iter_range:\n",
    "            results, result_file, pred, obs, rmse = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                            iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "            testrmse.append(rmse)\n",
    "\n",
    "return pred[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "# Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# # Making sure dimensionless bond length is less than 1\n",
    "# def bond(bl):\n",
    "#     return bl-1.0\n",
    "\n",
    "# Making sure dimensionless bond length is less than 1\n",
    "def bond(bl):\n",
    "    bln = -bl*(bl<0)\n",
    "    blp = bl*(bl>=1.0) - 1*(bl>=1.0)\n",
    "    return bln+blp\n",
    "\n",
    "# # Making sure final porosity is less than initial\n",
    "# def poros(poroi, porof):\n",
    "# #     porof[porof < 0] = 1-porof[porof < 0]\n",
    "#     porof[porof < 0] = poroi[0]-porof[porof < 0]\n",
    "#     print(porof)\n",
    "#     return porof-poroi\n",
    "\n",
    "# Making sure final porosity is less than initial\n",
    "def poros(poroi, porof):\n",
    "    porofn = -porof*(porof<0)\n",
    "    porofp = porof*(porof>=poroi) - poroi*(porof>=poroi)\n",
    "    return porofp+porofn\n",
    "\n",
    "# def strength(bl, porof, nlayer=6):\n",
    "#     discp = []\n",
    "#     sigma01, sigma02 = 6, 31\n",
    "#     C1s = 21\n",
    "#     sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "# #     print(\"sigma_long:\",sigma_long)\n",
    "#     for i in range(len(sigma_long)):\n",
    "#         for j in range(i + 1, len(sigma_long)):\n",
    "#             if (sigma_long[j] > sigma_long[i]):\n",
    "#                 discp.append(bl[i] - bl[j])\n",
    "#     discp = np.array(discp)\n",
    "#     print(discp)\n",
    "#     return discp\n",
    "\n",
    "def strength1(bl, porof, nlayer=6):\n",
    "    sigma01, sigma02 = 6, 31\n",
    "    C1s = 21\n",
    "    sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "    sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "    ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "    bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "    corr_bl_sorted = np.sort(bl, axis=-1)  # sorts along first axis (down)\n",
    "    return corr_bl_sorted-bl_sorted\n",
    "\n",
    "def strength2(bl, porof, nlayer=6):\n",
    "    sigma01, sigma02 = 6, 31\n",
    "    C1s = 21\n",
    "    sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "    sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "    ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "    bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "    return sum(bl_sorted[1:]-bl_sorted[:-1]<0)/14\n",
    "\n",
    "def phy_loss_mean(params):\n",
    "    # useful for cross-checking training\n",
    "    loss1, loss2, loss3, loss4, lam1, lam2 = params\n",
    "    x1, x2, x3 = loss1*(loss1>0), loss2*(loss2>0), loss3*(loss3>0)\n",
    "#     print(np.mean(x1), x1.shape[0])\n",
    "#     print(np.mean(x2), x2.shape[0])\n",
    "#     print(np.mean(x3), x3.shape[0])\n",
    "    \n",
    "    if x1.any() and x1.shape[0]>1:\n",
    "        X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "        x1 = X_scaled1\n",
    "    if x2.any() and x2.shape[0]>1:\n",
    "        X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "        x2 = X_scaled2\n",
    "    if x3.any() and x3.shape[0]>1:\n",
    "        X_scaled3 = (x3 - np.min(x3)) / (np.max(x3) - np.min(x3))\n",
    "        x3 = X_scaled3\n",
    "    return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3))\n",
    "#     return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3) + lam2*loss4)\n",
    "\n",
    "# def phy_loss_mean(params):\n",
    "#     # useful for cross-checking training\n",
    "#     diff1, diff2, lam1, lam2 = params\n",
    "#     x1, x2 = diff1*(diff1>0), diff2*(diff2>0)\n",
    "#     if np.any(x1):\n",
    "#         X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "#         x1 = X_scaled1\n",
    "#     if np.any(x2):\n",
    "#         X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "#         x2 = X_scaled2\n",
    "#     return lam1*np.mean(x1) + lam2*np.mean(x2)\n",
    "\n",
    "def PGNN_train_test(optimizer_name, optimizer_val, drop_rate, iteration, n_layers, n_nodes, tr_size, lamda, reg):\n",
    "        \n",
    "    # Hyper-parameters of the training process\n",
    "#     batch_size = int(tr_size/2)\n",
    "    batch_size = 2\n",
    "    num_epochs = 200\n",
    "    val_frac = 0.2\n",
    "    patience_val = 50\n",
    "    \n",
    "    # Initializing results filename\n",
    "    exp_name = optimizer_name + '_drop' + str(drop_rate) + '_nL' + str(n_layers) + '_nN' + str(n_nodes) + '_trsize' + str(tr_size) + '_iter' + str(iteration)\n",
    "    exp_name = exp_name.replace('.','pt')\n",
    "    results_dir = '../results/'\n",
    "    model_name = results_dir + exp_name + '_NoPhyInfomodel.h5' # storing the trained model\n",
    "    if reg:\n",
    "        results_name = results_dir + exp_name + '_results_regularizer.dat' # storing the results of the model\n",
    "    else:\n",
    "        results_name = results_dir + exp_name + '_results.dat' # storing the results of the model\n",
    "    \n",
    "    # Load labeled data\n",
    "    data = np.loadtxt('../data/labeled_data.dat')\n",
    "#     data = np.loadtxt('../data/labeled_data_BK_constw_unique.dat')\n",
    "#     data = np.loadtxt('../data/labeled_data_BK_constw_v2.dat')\n",
    "    x_labeled = data[:, :-5] # -2 because we do not need porosity predictions\n",
    "    y_labeled = data[:, -3:-1]\n",
    "\n",
    "    # normalize dataset with MinMaxScaler\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0, 1.0))\n",
    "#     scaler = preprocessing.StandardScaler()\n",
    "    x_labeled = scaler.fit_transform(x_labeled)\n",
    "#     y_labeled = scaler.fit_transform(y_labeled)\n",
    "    \n",
    "    # train and test data\n",
    "    trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "#     testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "#     init_poro = data[tr_size:, -1]\n",
    "    testX, testY = x_labeled[20:,:], y_labeled[20:]\n",
    "    init_poro = data[20:, -1]\n",
    "    \n",
    "    # Creating the model\n",
    "    model = Sequential()\n",
    "    for layer in np.arange(n_layers):\n",
    "        if layer == 0:\n",
    "            model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "        else:\n",
    "            if reg:\n",
    "                model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=.001, l2=.001)))\n",
    "            else:\n",
    "                model.add(Dense(n_nodes, activation='relu'))\n",
    "        model.add(Dropout(rate=drop_rate))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer_val,\n",
    "                  metrics=[root_mean_squared_error])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val,verbose=1)\n",
    "    \n",
    "    print('Running...' + optimizer_name)\n",
    "    history = model.fit(trainX, trainY,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        verbose=0,\n",
    "                        validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "\n",
    "    test_score = model.evaluate(testX, testY, verbose=1)\n",
    "    \n",
    "    predictions = model.predict(testX)\n",
    "#     inv_pred = scaler.inverse_transform(predictions)\n",
    "    phyloss1 = bond(predictions[:,0]) # physics loss 1\n",
    "    \n",
    "#     init_poro_ndim = np.ones((init_poro.shape))\n",
    "#     diff2 = poros(init_poro_ndim, predictions[:,1]) # physics loss 2\n",
    "    \n",
    "    phyloss2 = poros(init_poro, predictions[:,1]) # physics loss 2\n",
    "    phyloss3 = strength1(predictions[:,0], predictions[:,1])\n",
    "    phyloss4 = strength2(predictions[:,0], predictions[:,1])\n",
    "    \n",
    "    lam1, lam2 = lamda[0], lamda[1]    \n",
    "    phyloss = phy_loss_mean([phyloss1, phyloss2, phyloss3, phyloss4, lam1, lam2])\n",
    "    \n",
    "    print('iter: ' + str(iteration) + \n",
    "          ' nL: ' + str(n_layers) + ' nN: ' + str(n_nodes) + \n",
    "          ' trsize: ' + str(tr_size) + \n",
    "          ' TestRMSE: ' + str(test_score[1]) + ' PhyLoss: ' + str(phyloss), \"\\n\")\n",
    "    \n",
    "#     model.save(model_name)\n",
    "    \n",
    "    # save results\n",
    "    results = {'train_rmse':history.history['root_mean_squared_error'], \n",
    "                                'val_rmse':history.history['val_root_mean_squared_error'],\n",
    "                                'test_rmse':test_score[1], 'PhyLoss':phyloss}\n",
    "\n",
    "#     save_obj(results, results_name)\n",
    "    \n",
    "    return results, results_name, predictions, testY, test_score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...Adadelta\n",
      "19/19 [==============================] - 0s 0us/step\n",
      "iter: 0 nL: 2 nN: 10 trsize: 20 TestRMSE: 0.03165408968925476 PhyLoss: 0.3190250157598523 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main Function\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    fix_seeds(1)\n",
    "    \n",
    "    # List of optimizers to choose from    \n",
    "    optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "    optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "    \n",
    "    # selecting the optimizer\n",
    "    optimizer_num = 1\n",
    "    optimizer_name = optimizer_names[optimizer_num]\n",
    "    optimizer_val = optimizer_vals[optimizer_num]\n",
    "    \n",
    "    # Selecting Other Hyper-parameters\n",
    "    drop_rate = 0 # Fraction of nodes to be dropped out\n",
    "    n_layers = 2 # Number of hidden layers\n",
    "    n_nodes = 10 # Number of nodes per hidden layer\n",
    "\n",
    "    # Iterating over different training fractions and splitting indices for train-test splits\n",
    "    trsize_range = [4,6,8,10,20]\n",
    "    \n",
    "    #default training size = 5000\n",
    "    tr_size = trsize_range[4]\n",
    "    \n",
    "    # use regularizer\n",
    "    reg = True\n",
    "    \n",
    "    #set lamda=0 for pgnn0\n",
    "    lamda = [1, 1] # Physics-based regularization constant\n",
    "    \n",
    "    # total number of runs\n",
    "    iter_range = np.arange(1)\n",
    "    testrmse=[]\n",
    "    # iterating through all possible params\n",
    "    for iteration in iter_range:\n",
    "        results, result_file, pred, obs, rmse = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                        iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "        testrmse.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statistics import stdev\n",
    "# print(sum(testrmse) / len(testrmse),stdev(testrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02762699,  0.02762699,  0.03802956,  0.03504835,  0.02346394,\n",
       "        0.00829929, -0.01345009,  0.03504835,  0.02508554,  0.01711693,\n",
       "        0.02346394,  0.0320343 ,  0.03357953,  0.04504723, -0.00374251,\n",
       "        0.00829929, -0.02002536,  0.02762699,  0.03781087], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(obs[:,0], obs[:,1], 'd')\n",
    "plt.plot(pred[:,0], pred[:,1], '*')\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('RMSE')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(pred, \"../results_BK_v2_cnstTest/pred_nn.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict keys are: \n",
      "['train_rmse', 'val_rmse', 'test_rmse', 'PhyLoss']\n",
      "Test RMSE:  0.0845550000667572 PhyLoss:  0.8637055499213082\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_keys = []\n",
    "\n",
    "# get key and value \n",
    "print (\"Dict keys are: \") \n",
    "for key, value in results.items(): \n",
    "    dict_keys.append(key)\n",
    "\n",
    "print(dict_keys)\n",
    "train_rmse = results[dict_keys[0]]\n",
    "val_rmse = results[dict_keys[1]]\n",
    "test_rmse = results[dict_keys[2]]\n",
    "PhyLoss = results[dict_keys[3]]\n",
    "print(\"Test RMSE: \",test_rmse,\"PhyLoss: \", PhyLoss)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(train_rmse)\n",
    "plt.plot(val_rmse)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
