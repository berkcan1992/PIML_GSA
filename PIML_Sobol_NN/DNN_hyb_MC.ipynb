{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "import random\n",
    "\n",
    "def pass_arg(nsim, tr_size):\n",
    "    print(\"Tr_size:\", tr_size)\n",
    "    def fix_seeds(seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    #     K.set_session(sess)\n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    ss = 1\n",
    "    fix_seeds(ss)\n",
    "\n",
    "    # MC dropout\n",
    "    class MCDropout(Dropout):\n",
    "        def call(self, inputs, training=None):\n",
    "            return super(MCDropout, self).call(inputs, training=True)\n",
    "\n",
    "    # import pickle\n",
    "\n",
    "    # def save_obj(obj, name):\n",
    "    #     with open(name, 'wb') as f:\n",
    "    #         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "    # # Making sure dimensionless bond length is less than 1\n",
    "    # def bond(bl):\n",
    "    #     return bl-1.0\n",
    "\n",
    "    # Making sure dimensionless bond length is less than 1\n",
    "    def bond(bl):\n",
    "        bln = -bl*(bl<0)\n",
    "        blp = bl*(bl>=1.0) - 1*(bl>=1.0)\n",
    "        return bln+blp\n",
    "\n",
    "    # # Making sure final porosity is less than initial\n",
    "    # def poros(poroi, porof):\n",
    "    # #     porof[porof < 0] = 1-porof[porof < 0]\n",
    "    #     porof[porof < 0] = poroi[0]-porof[porof < 0]\n",
    "    #     print(porof)\n",
    "    #     return porof-poroi\n",
    "\n",
    "    # Making sure final porosity is less than initial\n",
    "    def poros(poroi, porof):\n",
    "        porofn = -porof*(porof<0)\n",
    "        porofp = porof*(porof>=poroi) - poroi*(porof>=poroi)\n",
    "        return porofp+porofn\n",
    "\n",
    "    def strength1(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        corr_bl_sorted = np.sort(bl, axis=-1)  # sorts along first axis (down)\n",
    "        return corr_bl_sorted-bl_sorted\n",
    "\n",
    "    def strength2(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        return sum(bl_sorted[1:]-bl_sorted[:-1]<0)/14\n",
    "\n",
    "    def phy_loss_mean(params):\n",
    "        # useful for cross-checking training\n",
    "        loss1, loss2, loss3, loss4, lam1, lam2 = params\n",
    "        x1, x2, x3 = loss1*(loss1>0), loss2*(loss2>0), loss3*(loss3>0)\n",
    "\n",
    "        if x1.any() and x1.shape[0]>1:\n",
    "            X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "            x1 = X_scaled1\n",
    "        if x2.any() and x2.shape[0]>1:\n",
    "            X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "            x2 = X_scaled2\n",
    "        if x3.any() and x3.shape[0]>1:\n",
    "            X_scaled3 = (x3 - np.min(x3)) / (np.max(x3) - np.min(x3))\n",
    "            x3 = X_scaled3\n",
    "        return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3))\n",
    "    #     return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3) + lam2*loss4)\n",
    "\n",
    "    def PGNN_train_test(optimizer_name, optimizer_val, drop_rate, iteration, n_layers, n_nodes, tr_size, lamda, reg):\n",
    "\n",
    "        # Hyper-parameters of the training process\n",
    "    #     batch_size = int(tr_size/2)\n",
    "        batch_size = 1\n",
    "        num_epochs = 50\n",
    "        val_frac = 0.2\n",
    "        patience_val = 50\n",
    "\n",
    "        # Initializing results filename\n",
    "        exp_name = \"FeatureEng_\" + optimizer_name + '_drop' + str(drop_rate) + '_nL' + str(n_layers) + '_nN' + str(n_nodes) + '_trsize' + str(tr_size) + '_iter' + str(iteration)\n",
    "        exp_name = exp_name.replace('.','pt')\n",
    "        results_dir = '../results/'\n",
    "        model_name = results_dir + exp_name + '_NoPhyInfomodel.h5' # storing the trained model\n",
    "        if reg:\n",
    "            results_name = results_dir + exp_name + '_results_regularizer.dat' # storing the results of the model\n",
    "        else:\n",
    "            results_name = results_dir + exp_name + '_results.dat' # storing the results of the model\n",
    "\n",
    "        # Load labeled data\n",
    "        data = np.loadtxt('../data/labeled_data.dat')\n",
    "\n",
    "        # x_labeled = data[:, :-5] # -2 because we do not need porosity predictions\n",
    "        x_label = data[:, :-3] # -2 because we do not need porosity predictions\n",
    "        x_labeled = np.hstack((x_label[:,:2],x_label[:,-2:]))\n",
    "        y_labeled = data[:, -3:-1]\n",
    "\n",
    "        # normalize dataset with MinMaxScaler\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range=(0, 1.0))\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "        x_labeled = scaler.fit_transform(x_labeled)\n",
    "#         y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "        # train and test data\n",
    "        trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "    #     testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "    #     init_poro = data[tr_size:, -1]\n",
    "        testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "        init_poro = data[tr_size:, -1]\n",
    "\n",
    "        # Creating the model\n",
    "        model = Sequential()\n",
    "        for layer in np.arange(n_layers):\n",
    "            if layer == 0:\n",
    "                model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "            else:\n",
    "                if reg:\n",
    "                    model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=.001, l2=.001)))\n",
    "                else:\n",
    "                    model.add(Dense(n_nodes, activation='relu'))\n",
    "            # model.add(Dropout(rate=drop_rate))\n",
    "            model.add(MCDropout(rate=drop_rate))\n",
    "        model.add(Dense(2, activation='linear'))\n",
    "\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizer_val,\n",
    "                      metrics=[root_mean_squared_error])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val,verbose=1)\n",
    "\n",
    "        print('Running...' + optimizer_name)\n",
    "        history = model.fit(trainX, trainY,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=num_epochs,\n",
    "                            verbose=0,\n",
    "                            validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "\n",
    "        test_score = model.evaluate(testX, testY, verbose=1)\n",
    "        print(test_score)\n",
    "        # predictions = model.predict(testX)\n",
    "    # #     inv_pred = scaler.inverse_transform(predictions)\n",
    "        # phyloss1 = bond(predictions[:,0]) # physics loss 1\n",
    "\n",
    "    # #     init_poro_ndim = np.ones((init_poro.shape))\n",
    "    # #     diff2 = poros(init_poro_ndim, predictions[:,1]) # physics loss 2\n",
    "\n",
    "        # phyloss2 = poros(init_poro, predictions[:,1]) # physics loss 2\n",
    "        # phyloss3 = strength1(predictions[:,0], predictions[:,1])\n",
    "        # phyloss4 = strength2(predictions[:,0], predictions[:,1])\n",
    "\n",
    "        # lam1, lam2 = lamda[0], lamda[1]    \n",
    "        # phyloss = phy_loss_mean([phyloss1, phyloss2, phyloss3, phyloss4, lam1, lam2])\n",
    "\n",
    "        # print('iter: ' + str(iteration) + \n",
    "              # ' nL: ' + str(n_layers) + ' nN: ' + str(n_nodes) + \n",
    "              # ' trsize: ' + str(tr_size) + \n",
    "              # ' TestRMSE: ' + str(test_score[1]) + ' PhyLoss: ' + str(phyloss), \"\\n\")\n",
    "\n",
    "    # #     model.save(model_name)\n",
    "\n",
    "        # # save results\n",
    "        # results = {'train_rmse':history.history['root_mean_squared_error'], \n",
    "                                    # 'val_rmse':history.history['val_root_mean_squared_error'],\n",
    "                                    # 'test_rmse':test_score[1], 'PhyLoss':phyloss}\n",
    "\n",
    "    #     save_obj(results, results_name)\n",
    "\n",
    "        # return results, results_name, predictions, testY, test_score[1]\n",
    "        # predictions = model.predict(Xx)\n",
    "        Xx = np.random.uniform(0,1,(1000,2))\n",
    "        xx1 = np.ones((1000,2))\n",
    "        Xx = np.hstack((Xx,xx1))\n",
    "        \n",
    "        samples = []\n",
    "        for i in range(int(nsim)):\n",
    "#             print(\"simulation num:\",i)\n",
    "            predictions = model.predict(Xx)\n",
    "            predictions = predictions[:,1]\n",
    "            samples.append(predictions)\n",
    "        return np.array(samples)\n",
    "\n",
    "\n",
    "    # Main Function\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        fix_seeds(1)\n",
    "\n",
    "        # List of optimizers to choose from    \n",
    "        optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "        optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "\n",
    "        # selecting the optimizer\n",
    "        optimizer_num = 1\n",
    "        optimizer_name = optimizer_names[optimizer_num]\n",
    "        optimizer_val = optimizer_vals[optimizer_num]\n",
    "\n",
    "        # Selecting Other Hyper-parameters\n",
    "        drop_rate = 0.1 # Fraction of nodes to be dropped out\n",
    "        n_layers = 2 # Number of hidden layers\n",
    "        n_nodes = 5 # Number of nodes per hidden layer\n",
    "\n",
    "        # # Iterating over different training fractions and splitting indices for train-test splits\n",
    "        # trsize_range = [4,6,8,10,20]\n",
    "\n",
    "        # #default training size = 5000\n",
    "        # tr_size = trsize_range[4]\n",
    "\n",
    "        tr_size = int(tr_size)\n",
    "\n",
    "        # use regularizer\n",
    "        reg = True\n",
    "\n",
    "        #set lamda=0 for pgnn0\n",
    "        lamda = [1, 1] # Physics-based regularization constant\n",
    "\n",
    "        # total number of runs\n",
    "        iter_range = np.arange(1)\n",
    "        testrmse=[]\n",
    "        # iterating through all possible params\n",
    "        for iteration in iter_range:\n",
    "            # results, result_file, pred, obs, rmse = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                            # iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "            # testrmse.append(rmse)\n",
    "            pred = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                            iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "    \n",
    "    return np.squeeze(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr_size: 20\n",
      "Running...Adadelta\n",
      "19/19 [==============================] - 0s 0us/step\n",
      "[0.02474483847618103, 0.10644947737455368]\n"
     ]
    }
   ],
   "source": [
    "pred = pass_arg(50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.69186348e-02,  8.01319405e-02,  2.34705303e-02,  1.55689672e-01,\n",
       "        1.99153334e-01, -5.12664169e-02,  2.51775742e-01,  2.85439938e-01,\n",
       "        5.54168113e-02,  4.04932834e-02,  1.14963681e-01,  2.43973672e-01,\n",
       "        2.94261932e-01,  2.28196979e-01,  2.68822759e-01,  9.02395248e-02,\n",
       "        2.07766175e-01,  2.97987461e-01,  2.77992547e-01, -1.14477240e-02,\n",
       "        1.28755525e-01,  1.74248219e-01, -5.58200199e-03,  1.99817479e-01,\n",
       "        3.77775058e-02,  2.89024543e-02,  9.44234952e-02,  2.86427051e-01,\n",
       "        3.02879423e-01,  9.34898295e-03,  2.49078453e-01,  9.75074843e-02,\n",
       "        1.20359696e-01,  2.06552848e-01,  2.28148133e-01,  2.05474067e-03,\n",
       "        2.04362884e-01,  2.44329706e-01,  6.05485067e-02,  1.38857380e-01,\n",
       "       -1.54986966e-03,  8.86856467e-02,  2.29040720e-02, -2.79347459e-03,\n",
       "        4.69710641e-02,  1.77176803e-01,  2.38744449e-02,  9.99162160e-03,\n",
       "        1.34434983e-01,  1.50236618e-02,  3.38357210e-01,  2.02895492e-01,\n",
       "        1.89899266e-01,  9.01915580e-02,  4.27198708e-02,  7.25135580e-03,\n",
       "        2.81540394e-01,  7.69703612e-02,  6.29298463e-02,  2.35712036e-01,\n",
       "       -3.26086394e-02,  2.35310808e-01,  1.53826289e-02,  7.96286613e-02,\n",
       "        9.72096249e-02,  3.78324948e-02,  3.02800804e-01,  1.52784422e-01,\n",
       "        1.41414374e-01,  5.21082245e-02,  1.27442896e-01,  3.03350478e-01,\n",
       "       -1.70246009e-02, -5.15168756e-02,  2.23084629e-01,  2.47450173e-01,\n",
       "        2.96121389e-01,  1.03948809e-01, -2.03456171e-02,  2.74452776e-01,\n",
       "        2.91756928e-01, -4.67072390e-02,  5.98080903e-02,  2.35839915e-02,\n",
       "        1.87947880e-02, -8.66304897e-03, -1.05130412e-02, -2.87721492e-02,\n",
       "       -2.90873535e-02,  2.83546716e-01,  2.72162277e-02,  1.68212071e-01,\n",
       "        4.70291264e-02, -4.83210646e-02,  1.76893119e-02,  8.62363726e-02,\n",
       "        1.49205700e-02,  2.66962219e-02,  7.67146572e-02,  1.98826700e-01,\n",
       "        3.85535583e-02,  3.39381754e-01,  8.88540968e-02,  2.96916142e-02,\n",
       "        1.73285216e-01,  5.29625714e-02,  1.52580142e-02,  2.85349280e-01,\n",
       "        1.24401692e-02,  2.30371490e-01,  2.99872041e-01, -1.01092206e-02,\n",
       "        1.03489853e-01,  6.25840575e-02,  1.13589853e-01,  1.86549395e-01,\n",
       "        1.56709239e-01,  6.59503043e-02,  8.21834877e-02,  3.55493613e-02,\n",
       "        2.81315058e-01,  3.58377434e-02, -8.45216662e-02,  8.28616172e-02,\n",
       "       -2.19437145e-02,  3.04922670e-01,  3.74477543e-02, -8.36953148e-03,\n",
       "       -6.21613786e-02,  2.08084911e-01,  1.89559050e-02,  1.35534197e-01,\n",
       "        3.40673596e-01,  1.24232076e-01,  1.57726519e-02,  5.25556244e-02,\n",
       "       -7.60300085e-02,  2.07079023e-01,  3.19932476e-02,  1.42963216e-01,\n",
       "       -3.70810600e-03,  1.99968815e-01,  2.92231649e-01,  1.91548645e-01,\n",
       "        3.14984620e-01,  1.89829711e-02,  1.81941465e-01,  4.74006459e-02,\n",
       "        1.85060516e-01, -4.56930399e-02,  3.63432467e-02,  2.89178282e-01,\n",
       "        1.03164949e-01,  1.99696764e-01,  1.30788207e-01,  3.02293360e-01,\n",
       "        3.33795965e-01,  2.07252145e-01,  2.71626174e-01,  3.09256911e-01,\n",
       "        3.07889096e-02,  2.02649742e-01,  3.14815342e-02,  7.75311962e-02,\n",
       "        8.92741606e-02,  2.05970541e-01,  2.15050548e-01, -1.29329786e-02,\n",
       "       -2.83591151e-02,  2.92622060e-01, -7.04151753e-04,  9.49876010e-02,\n",
       "        4.09443863e-02,  4.84153070e-02,  2.37278029e-01,  8.24044794e-02,\n",
       "        5.30649647e-02,  1.99437499e-01, -6.57130554e-02,  1.70951769e-01,\n",
       "       -4.07401770e-02, -2.32687481e-02,  2.94332355e-02,  3.33302885e-01,\n",
       "        4.19422239e-02,  3.54987942e-02, -5.34128956e-02,  3.54953647e-01,\n",
       "        4.52089980e-02,  1.01791173e-01,  6.21016882e-02, -7.00115189e-02,\n",
       "        1.68639749e-01,  1.24080613e-01,  8.68380517e-02,  2.95594037e-01,\n",
       "       -6.07226044e-02,  5.57700917e-02, -4.44450825e-02,  2.23447248e-01,\n",
       "        2.91763812e-01,  4.64885719e-02,  4.09950577e-02,  8.06735456e-02,\n",
       "        3.03212017e-01,  3.16998094e-01,  2.32116222e-01,  9.66436565e-02,\n",
       "        4.01488645e-03, -3.06065772e-02,  1.34200275e-01, -1.55141214e-02,\n",
       "        3.04883003e-01, -7.36520365e-02, -2.10560448e-02,  3.09121430e-01,\n",
       "        1.85403123e-01,  3.96163166e-02,  1.29733175e-01,  1.03588998e-01,\n",
       "        1.70043424e-01,  9.41656604e-02,  1.49337262e-01, -4.50545922e-03,\n",
       "        3.35728616e-01,  6.91705476e-03, -4.59921993e-02,  1.09978572e-01,\n",
       "        2.03264102e-01,  3.16881567e-01, -4.50396016e-02,  2.10760772e-01,\n",
       "        2.49764919e-01,  3.07385754e-02,  1.33130461e-01,  1.42740170e-02,\n",
       "        4.59922180e-02,  1.86155587e-01,  2.27979142e-02,  2.07026321e-02,\n",
       "        2.09710851e-01, -8.58955607e-02, -1.01320092e-02,  1.64754659e-01,\n",
       "        1.30356044e-01,  6.87031969e-02,  2.88773358e-01,  2.34354630e-01,\n",
       "        2.12046430e-02,  1.05155207e-01, -1.96019821e-02,  3.19172889e-01,\n",
       "        1.41578957e-01,  3.33622545e-02,  2.73360550e-01,  1.63080305e-01,\n",
       "       -2.44676979e-04,  1.98900342e-01,  1.19069129e-01, -6.70877621e-02,\n",
       "        8.69321078e-02,  1.11384042e-01,  4.87431251e-02, -4.84494828e-02,\n",
       "        9.18503404e-02,  1.84163645e-01,  2.18230113e-01,  1.48497000e-02,\n",
       "        4.35142182e-02, -1.79853849e-02,  2.58017937e-03,  5.24294600e-02,\n",
       "       -7.43040517e-02,  1.50366962e-01,  1.66302189e-01,  1.05911329e-01,\n",
       "        2.38674253e-01,  1.80590928e-01,  1.18058942e-01,  3.20930928e-02,\n",
       "        1.74512371e-01,  1.12982422e-01, -7.42321536e-02, -3.79274748e-02,\n",
       "        1.33162439e-01, -7.55056664e-02,  1.67817473e-01, -6.57055713e-03,\n",
       "        4.64257188e-02,  8.93349871e-02,  1.51825687e-02, -3.38455080e-03,\n",
       "       -1.28762247e-02,  3.60112861e-02,  1.10992528e-01,  4.62313183e-02,\n",
       "        1.93430036e-01, -2.73628775e-02,  1.63785934e-01,  6.91575706e-02,\n",
       "        3.43341716e-02,  1.75637320e-01, -3.49316746e-02, -3.81525606e-02,\n",
       "        6.28699809e-02, -6.79596737e-02,  3.62646356e-02,  6.09676167e-02,\n",
       "        1.57199740e-01,  4.34578620e-02,  4.49877456e-02,  1.18082173e-01,\n",
       "        2.54624605e-01, -2.88264602e-02,  5.64817302e-02,  5.36813121e-03,\n",
       "        3.17344427e-01, -1.28196813e-02,  1.95884854e-01, -1.91188622e-02,\n",
       "       -3.54554132e-02,  9.24660563e-02,  6.14234060e-02,  2.54426859e-02,\n",
       "       -3.24301682e-02, -2.55614407e-02,  1.71369061e-01,  2.07205340e-01,\n",
       "       -2.07242984e-02,  2.47742563e-01,  7.69334063e-02,  5.05955927e-02,\n",
       "        1.32173598e-01,  7.20711499e-02,  2.28072256e-01,  2.34973550e-01,\n",
       "       -9.48438141e-03,  9.46752634e-03,  6.84967590e-03,  1.59966171e-01,\n",
       "        2.84171373e-01, -5.14653185e-03, -5.04240133e-02,  3.22076604e-02,\n",
       "        2.07114518e-01,  1.92848593e-01,  1.34144157e-01, -2.44715568e-02,\n",
       "        3.97898778e-02,  3.66661921e-02,  7.72134960e-02,  1.22294098e-01,\n",
       "        2.86984086e-01, -1.25626298e-02, -5.29940873e-02,  1.59294847e-02,\n",
       "       -8.72066990e-03,  9.71684828e-02,  9.84968394e-02,  3.97300683e-02,\n",
       "        4.86889780e-02,  1.34715736e-02, -1.51919834e-02,  2.79806517e-02,\n",
       "       -2.63350084e-02, -6.10054955e-02,  1.19986735e-01, -6.79284409e-02,\n",
       "        1.67230546e-01, -6.91853017e-02,  2.65157402e-01,  1.12137996e-01,\n",
       "        4.54403833e-02,  2.75457948e-01,  1.21340873e-02,  1.41886145e-01,\n",
       "        1.71513841e-01,  1.81662440e-01,  1.61943376e-01,  2.73851991e-01,\n",
       "        1.68271556e-01, -1.16384290e-02,  3.10611296e-02,  2.92201728e-01,\n",
       "        4.47809733e-02,  2.07452103e-01, -8.84331912e-02,  3.82876664e-01,\n",
       "        1.21415116e-01,  1.28623769e-01,  2.52512068e-01, -2.78472025e-02,\n",
       "        1.61083028e-01, -1.70145873e-02,  2.11605012e-01,  9.12630260e-02,\n",
       "       -3.05318721e-02,  2.12278932e-01,  8.16986784e-02,  3.67420644e-01,\n",
       "        2.47880191e-01,  1.02684321e-02, -4.63427939e-02,  5.41662872e-02,\n",
       "        1.61249638e-01,  2.73254216e-01,  1.42015696e-01,  2.71457084e-03,\n",
       "        1.59134880e-01,  1.55484557e-01,  2.69456476e-01,  5.87257817e-02,\n",
       "        2.52457082e-01, -6.74518123e-02,  4.54570614e-02,  3.21969479e-01,\n",
       "        2.79454067e-02,  3.36337313e-02,  2.26817697e-01,  7.62317106e-02,\n",
       "        1.11144684e-01, -4.48682681e-02, -1.33946743e-02,  1.59429416e-01,\n",
       "        1.09320275e-01, -3.76864150e-02,  2.51646470e-02,  1.04167469e-01,\n",
       "        1.77314088e-01,  2.54574902e-02,  1.01168491e-01,  3.29302698e-01,\n",
       "       -3.74225737e-03, -1.58864263e-04,  2.02644374e-02,  2.60022134e-01,\n",
       "        2.52047420e-01,  1.89810604e-01,  5.04585616e-02, -1.16793681e-02,\n",
       "        2.75877658e-02,  6.02611937e-02,  1.65132046e-01,  1.04567297e-01,\n",
       "       -1.77247841e-02, -5.38516417e-02,  1.39107816e-02,  2.67845809e-01,\n",
       "        2.20974490e-01, -6.20370312e-03,  1.79480642e-01,  2.73592204e-01,\n",
       "       -3.55279185e-02,  3.32219094e-01, -2.60969996e-02,  1.16665117e-01,\n",
       "        2.81473678e-02,  3.27817351e-01, -8.44212901e-03,  1.19014949e-01,\n",
       "        9.37285647e-02,  4.51401249e-02,  4.64433730e-02, -3.21789756e-02,\n",
       "       -2.66959574e-02,  2.34836116e-02,  1.85237840e-01,  1.33379683e-01,\n",
       "       -6.07283749e-02,  4.64508533e-02,  1.66296680e-02,  1.27491936e-01,\n",
       "        3.73997465e-02,  2.25503355e-01,  7.50588104e-02,  8.93908665e-02,\n",
       "        1.33386161e-02,  5.01046143e-02,  1.30157486e-01,  2.31530741e-01,\n",
       "        8.48989561e-02,  5.26457913e-02, -3.10749896e-02,  1.50434732e-01,\n",
       "       -1.18367048e-02,  2.96472192e-01,  2.48437732e-01, -1.85725112e-02,\n",
       "       -1.62039604e-03,  9.10687894e-02,  4.14751954e-02,  4.69071344e-02,\n",
       "        1.85895264e-01,  3.16949524e-02,  2.78069615e-01,  1.30429968e-01,\n",
       "        1.41278610e-01,  9.05540735e-02,  6.11516349e-02,  3.63715857e-01,\n",
       "        2.26996243e-01,  2.35693112e-01, -2.31696852e-02,  1.83261171e-01,\n",
       "        1.28450066e-01, -4.56483848e-02, -7.06045935e-03,  1.72756121e-01,\n",
       "       -1.23316776e-02, -6.01443276e-02,  2.31805816e-01,  3.37319076e-02,\n",
       "       -5.08136228e-02,  2.87667900e-01,  4.57996614e-02, -9.31189358e-02,\n",
       "        2.89185345e-01,  2.58623362e-01, -2.81034056e-02,  7.23228455e-02,\n",
       "        9.26252529e-02,  1.13834202e-01, -9.94545668e-02, -1.61014125e-02,\n",
       "        4.34972160e-02,  1.34364262e-01,  2.02073216e-01,  1.40852362e-01,\n",
       "        3.47666174e-01,  1.38599008e-01,  1.92358829e-02,  2.17013165e-01,\n",
       "       -5.54403812e-02,  6.23374293e-03,  1.54131129e-01,  1.25829205e-01,\n",
       "        2.30311409e-01,  1.60012990e-01, -8.29449371e-02,  1.10967904e-01,\n",
       "        3.27432990e-01,  2.06589162e-01,  1.47858024e-01,  1.29584163e-01,\n",
       "       -7.34720903e-04,  1.90745473e-01,  1.11687787e-01,  2.22520847e-02,\n",
       "        1.06034525e-01, -8.11717212e-02,  2.93990057e-02,  1.72013994e-02,\n",
       "        3.99619192e-02,  3.54935229e-02,  2.11505406e-02,  5.24985790e-02,\n",
       "        2.31716409e-02,  3.61129254e-01, -2.26583835e-02, -9.43377241e-03,\n",
       "       -4.53300029e-02,  2.79215425e-01,  1.23462230e-01, -3.84934172e-02,\n",
       "       -6.73400145e-03, -1.49744097e-02, -2.38708854e-02,  2.77230024e-01,\n",
       "        5.87014705e-02, -7.22490251e-02,  3.33340377e-01,  6.22023409e-03,\n",
       "        1.28619552e-01,  1.22796796e-01,  1.28999889e-01,  2.59719305e-02,\n",
       "        5.85035095e-03,  1.99752182e-01,  2.95634210e-01,  2.10115954e-01,\n",
       "        5.74098192e-02,  1.08084157e-02,  1.23035438e-01,  5.84967844e-02,\n",
       "        1.00921830e-02,  1.78767145e-01, -4.02200520e-02, -3.79309766e-02,\n",
       "        7.80807510e-02,  6.25133887e-02,  2.37440258e-01, -2.11507864e-02,\n",
       "        5.13468832e-02,  1.55324563e-01,  3.50541264e-01,  7.25576133e-02,\n",
       "        2.02811837e-01,  2.03858107e-01,  1.86210815e-02,  1.47779226e-01,\n",
       "        3.19222733e-02,  2.29887009e-01, -3.37428674e-02,  3.99948023e-02,\n",
       "        2.32354358e-01,  1.41793162e-01,  1.88643023e-01, -4.90825363e-02,\n",
       "        8.78920779e-02,  3.60419154e-01,  5.93822375e-02,  3.91382240e-02,\n",
       "        4.70885485e-02,  3.29110883e-02, -8.97080824e-02,  9.22640041e-03,\n",
       "       -4.43183668e-02,  3.32365595e-02,  2.53623966e-02,  6.27703592e-02,\n",
       "        1.44299522e-01,  8.34060758e-02,  1.30623519e-01, -3.94461341e-02,\n",
       "       -1.36890709e-02,  1.19314745e-01,  1.10877706e-02, -2.32306197e-02,\n",
       "        2.27075648e-02,  8.80702958e-02,  3.74758914e-02,  1.65466536e-02,\n",
       "        2.04173133e-01,  2.39199400e-03,  1.12743422e-01, -3.23858634e-02,\n",
       "        7.54205585e-02,  2.84161195e-02,  7.25539997e-02,  9.79605466e-02,\n",
       "        1.56964302e-01,  2.50430256e-01,  2.35507816e-01,  1.76279128e-01,\n",
       "        1.09609984e-01,  3.46656799e-01,  1.23982076e-02,  3.96039113e-02,\n",
       "        4.02007960e-02, -3.64917554e-02, -2.88478788e-02,  2.33257681e-01,\n",
       "        8.56769457e-02,  8.98495875e-03,  3.55883837e-01,  2.96356767e-01,\n",
       "        4.35153432e-02,  6.82510138e-02, -6.52454868e-02,  3.70661356e-02,\n",
       "       -5.07556684e-02,  7.50351138e-03,  4.11572456e-02,  8.26087594e-02,\n",
       "        1.11941788e-02,  1.24348579e-02, -2.24457607e-02,  2.12743431e-02,\n",
       "        7.09165931e-02,  2.32189059e-01,  5.92544451e-02,  2.24031925e-01,\n",
       "       -5.51130101e-02,  4.01105769e-02,  2.15783536e-01, -3.42788361e-02,\n",
       "        1.00892030e-01,  5.78997983e-03,  1.18953839e-01,  1.42087892e-01,\n",
       "        2.04762980e-01,  2.91014373e-01,  2.82323837e-01, -4.29637125e-03,\n",
       "        3.80369723e-01,  1.25313535e-01,  1.54874489e-01,  3.89543734e-02,\n",
       "        2.63256460e-01,  1.57279909e-01,  3.03472131e-01,  2.08380237e-01,\n",
       "        1.42874703e-01,  1.45429112e-02,  2.65481561e-01,  4.01455648e-02,\n",
       "       -1.32418694e-02,  2.53359288e-01,  1.98932514e-01,  1.73982263e-01,\n",
       "        6.25947714e-02, -4.96374890e-02, -4.87663001e-02,  4.25405102e-03,\n",
       "       -3.21289264e-02,  1.06863402e-01,  3.20260495e-01,  4.27034609e-02,\n",
       "        1.30853225e-02,  4.71308939e-02,  9.72434506e-02, -4.94993553e-02,\n",
       "        7.61141255e-03,  3.78992334e-02,  4.45596613e-02, -2.00039763e-02,\n",
       "       -2.00263858e-02,  6.83779409e-03,  1.70931831e-01,  2.25301869e-02,\n",
       "        4.45989706e-02,  2.07086578e-01,  2.17502385e-01,  3.93127427e-02,\n",
       "        1.31577000e-01,  6.93396255e-02, -1.32764066e-02,  1.20564796e-01,\n",
       "        8.37581754e-02,  2.43681297e-01, -1.50056342e-02,  4.68240455e-02,\n",
       "        1.48262277e-01,  7.76627734e-02,  2.10687861e-01,  1.99957624e-01,\n",
       "        4.43210155e-02, -2.58101756e-03,  3.23663294e-01, -2.41138451e-02,\n",
       "        3.15388441e-01,  8.05686563e-02,  5.26404753e-02,  1.48088962e-01,\n",
       "       -9.92887653e-03, -4.67213988e-03, -4.88295071e-02,  2.70141393e-01,\n",
       "       -1.89578421e-02,  1.84488788e-01,  2.67251134e-02, -6.08919524e-02,\n",
       "        2.30294153e-01,  8.03749561e-02,  3.29736859e-01,  2.94148982e-01,\n",
       "        4.76431958e-02,  2.78682441e-01,  1.49903923e-01, -2.78984308e-02,\n",
       "        4.71296348e-03,  1.66421771e-01,  4.96993586e-02,  4.05306853e-02,\n",
       "       -6.49523064e-02,  2.48459689e-02,  5.26286475e-02,  2.45294888e-02,\n",
       "        2.28161111e-01,  1.61732793e-01,  2.34467275e-02, -1.98028665e-02,\n",
       "        1.17744751e-01,  3.30952615e-01,  1.47206292e-01,  2.27399305e-01,\n",
       "        1.35266187e-03,  1.05312094e-02,  2.63809979e-01,  3.16892982e-01,\n",
       "        1.04501627e-01,  2.81025358e-02,  1.10228978e-01, -4.44239564e-02,\n",
       "        1.54732605e-02,  2.34867692e-01,  4.36281264e-02,  3.10947523e-02,\n",
       "        2.18984482e-04,  2.30160758e-01,  2.44919136e-02,  3.51145752e-02,\n",
       "       -3.05775763e-03, -4.46939245e-02,  4.56234887e-02,  1.97150975e-01,\n",
       "        2.11628690e-01,  2.03166455e-02,  3.22054148e-01,  1.18657976e-01,\n",
       "        1.74697518e-01,  2.82498926e-01, -3.86363380e-02,  1.72105044e-01,\n",
       "        3.50491285e-01, -4.15237993e-02,  5.05765676e-02,  2.27600366e-01,\n",
       "        1.53630346e-01,  2.50926703e-01,  2.13300567e-02, -3.35753076e-02,\n",
       "        2.67000079e-01,  3.42196167e-01, -4.04352844e-02, -7.92371854e-03,\n",
       "        2.29001902e-02,  2.37415358e-01, -7.39646032e-02,  6.38954565e-02,\n",
       "       -4.89847958e-02,  1.31447732e-01,  3.20573896e-02,  2.51321375e-01,\n",
       "        1.99164242e-01,  1.90713584e-01,  1.60690993e-02,  2.37895340e-01,\n",
       "        1.25564337e-01,  1.15215190e-01,  4.57309112e-02,  2.85150141e-01,\n",
       "        3.37157100e-02,  1.49172500e-01,  5.19983545e-02,  2.84190327e-01,\n",
       "        2.91474223e-01,  4.65262309e-02, -3.31832729e-02,  3.62531126e-01,\n",
       "       -4.97095659e-03,  9.54333991e-02,  2.08409857e-02,  1.12585656e-01,\n",
       "        9.82376188e-02,  1.38702065e-01,  3.42521556e-02,  4.51326482e-02,\n",
       "        2.41030201e-01, -1.56081580e-02,  2.51389265e-01,  1.68051526e-01,\n",
       "       -9.24609005e-02,  5.22519201e-02,  1.35194242e-01, -5.88959455e-03,\n",
       "        1.00383617e-01,  1.73097732e-03,  4.40431125e-02,  1.93206742e-01,\n",
       "        3.49076279e-02,  3.02708060e-01,  1.20062418e-02,  2.47690886e-01,\n",
       "        2.11405799e-01,  5.17589040e-02,  1.82760239e-01, -1.87208655e-03,\n",
       "       -9.85182356e-03,  2.98591763e-01, -5.45966849e-02,  2.50179530e-03,\n",
       "        9.04944614e-02,  4.05599102e-02,  2.17368856e-01,  2.94404291e-02,\n",
       "        7.70920962e-02,  1.41900077e-01,  8.42990726e-03,  2.08744958e-01,\n",
       "        1.83771461e-01,  1.12947412e-02,  3.74444455e-01,  1.82887763e-01,\n",
       "        3.15776378e-01,  2.34908182e-02,  3.03694725e-01,  4.66590114e-02,\n",
       "        2.86621183e-01,  3.07303935e-01,  1.64535865e-01, -5.61574735e-02,\n",
       "       -5.55513659e-03, -3.70900184e-02,  4.17041779e-02,  9.29051787e-02,\n",
       "        7.65963569e-02, -5.06863259e-02,  1.03562176e-01,  3.20163697e-01,\n",
       "        3.33911628e-02,  4.08630483e-02,  2.56067157e-01,  1.43019453e-01,\n",
       "        1.65331662e-01,  1.47182420e-02,  2.61776745e-01, -1.59768220e-02,\n",
       "       -2.96576018e-03,  4.04246412e-02,  1.22683860e-01,  2.14704290e-01,\n",
       "        5.99886551e-02,  3.15274820e-02, -8.95093661e-03, -1.24956639e-02,\n",
       "        2.36483756e-02,  2.34903410e-01,  1.45549551e-01,  3.07133961e-02,\n",
       "        1.31333917e-01,  2.22293928e-01,  1.31676467e-02,  9.37969014e-02,\n",
       "       -2.71515585e-02, -3.18829380e-02,  2.50167772e-02, -2.05352288e-02,\n",
       "       -3.47633660e-02,  2.96238154e-01, -2.52810828e-02,  1.94426239e-01,\n",
       "        3.06695282e-01,  2.50400484e-01,  2.27540314e-01, -1.71027239e-02,\n",
       "        4.07663807e-02,  2.34207232e-02,  1.73365980e-01, -3.89083773e-02,\n",
       "        9.96720744e-04,  1.74797192e-01,  7.50270337e-02, -4.92439084e-02,\n",
       "        7.46658724e-03,  2.68256634e-01, -3.80235799e-02, -7.21435389e-03,\n",
       "        1.47887439e-01,  1.95744745e-02, -5.17421141e-02,  2.48173445e-01,\n",
       "        3.39931756e-01,  4.05888408e-02,  2.96432972e-01,  1.77562907e-01,\n",
       "       -2.35499050e-02,  3.27804722e-02, -8.09193403e-02,  1.41244352e-01,\n",
       "        1.68448940e-01,  1.14797972e-01,  2.89881825e-01,  9.36542898e-02,\n",
       "       -9.43819061e-03,  2.71975696e-01, -3.61318253e-02,  2.28362575e-01,\n",
       "        4.42622565e-02,  8.15420598e-03,  5.70864864e-02,  1.18346207e-01,\n",
       "        3.07239294e-02,  3.94783095e-02, -4.73930239e-04,  3.32822651e-01,\n",
       "        4.35692184e-02,  2.65981048e-01,  3.94541994e-02,  1.63353533e-02,\n",
       "        2.33039871e-01,  3.42386097e-01,  8.82850587e-02,  3.66868019e-01,\n",
       "        4.35295403e-02, -2.63336711e-02,  1.14051312e-01,  1.33240953e-01,\n",
       "        3.25954020e-01,  1.38173746e-02,  3.16007644e-01,  2.05941975e-01,\n",
       "        1.83036536e-01,  9.09542665e-02, -4.24962491e-02,  2.06669047e-01,\n",
       "        5.55936713e-04,  2.98403829e-01,  6.86645433e-02,  2.90280551e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_pred=np.mean(pred,axis=0)\n",
    "mc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_obj(mc_pred, \"../pred_hyb_MC_Xx.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
